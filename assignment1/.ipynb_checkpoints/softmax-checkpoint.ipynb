{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149d5b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/roark/Documents/Assignments/cs231n spring2023/assignment1/cs231n/datasets\n",
      "/home/roark/Documents/Assignments/cs231n spring2023/assignment1\n"
     ]
    }
   ],
   "source": [
    "# This mounts your Google Drive to the Colab VM.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
    "FOLDERNAME = '/home/roark/Documents/Assignments/cs231n\\ spring2023/assignment1'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# Now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "sys.path.append(FOLDERNAME)\n",
    "\n",
    "# This downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "# !bash get_datasets.sh\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME\n",
    "%cd $FOLDERNAME/cs231n/datasets/\n",
    "!bash get_datasets.sh\n",
    "%cd $FOLDERNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfc27e",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6cf2d4",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9bbbbe",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Clear previously loaded data.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3fb04",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside `cs231n/classifiers/softmax.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f2e5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.000000\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebc638",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$\n",
    "$$Loss = -\\frac{1}{N}∑_{i=1}^Nlog\\frac{e^{S_{yi}}}{∑_je^S_j}$$\n",
    "当w初始化为均值为0的极小值时，scores也大约为0附件的很小的值，因此$$e^{s_j}≈1$$\n",
    "$$-\\frac{1}{N}∑_{i=1}^Nlog\\frac{e^{S_{yi}}}{∑_je^S_j}≈-\\frac{1}{N}*N*log\\frac{1}{C}≈-log\\frac{1}{10}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8cb3eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 1.984006 analytic: 1.984006, relative error: 1.215261e-08\n",
      "numerical: 0.280166 analytic: 0.280166, relative error: 2.456681e-07\n",
      "numerical: -1.830063 analytic: -1.830063, relative error: 8.465970e-09\n",
      "numerical: 0.951770 analytic: 0.951770, relative error: 4.630116e-08\n",
      "numerical: -0.314469 analytic: -0.314469, relative error: 7.552750e-08\n",
      "numerical: 2.347862 analytic: 2.347861, relative error: 4.124545e-08\n",
      "numerical: -1.966719 analytic: -1.966719, relative error: 4.914964e-08\n",
      "numerical: 1.722155 analytic: 1.722155, relative error: 2.994074e-09\n",
      "numerical: -1.707501 analytic: -1.707502, relative error: 4.088156e-08\n",
      "numerical: 1.466980 analytic: 1.466980, relative error: 4.931098e-08\n",
      "numerical: 0.859069 analytic: 0.859069, relative error: 9.891797e-08\n",
      "numerical: -1.762354 analytic: -1.762354, relative error: 4.046263e-08\n",
      "numerical: 2.787771 analytic: 2.787771, relative error: 1.257655e-08\n",
      "numerical: 3.962173 analytic: 3.962173, relative error: 2.941702e-08\n",
      "numerical: -2.328267 analytic: -2.328267, relative error: 1.833141e-08\n",
      "numerical: 1.442370 analytic: 1.442370, relative error: 9.524430e-09\n",
      "numerical: 1.778301 analytic: 1.778301, relative error: 1.108561e-08\n",
      "numerical: 0.103375 analytic: 0.103375, relative error: 1.001253e-07\n",
      "numerical: -0.684841 analytic: -0.684841, relative error: 1.142955e-08\n",
      "numerical: -3.127639 analytic: -3.127639, relative error: 1.398269e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a4a81d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.348311e+00 computed in 0.050569s\n",
      "vectorized loss: 2.348311e+00 computed in 0.003150s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3453536",
   "metadata": {
    "tags": [
     "code"
    ],
    "test": "tuning"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 2000: loss 6.462815\n",
      "iteration 100 / 2000: loss 3.695388\n",
      "iteration 200 / 2000: loss 3.174832\n",
      "iteration 300 / 2000: loss 3.093095\n",
      "iteration 400 / 2000: loss 2.809655\n",
      "iteration 500 / 2000: loss 3.269984\n",
      "iteration 600 / 2000: loss 3.012376\n",
      "iteration 700 / 2000: loss 2.780530\n",
      "iteration 800 / 2000: loss 2.741740\n",
      "iteration 900 / 2000: loss 2.701695\n",
      "iteration 1000 / 2000: loss 2.672581\n",
      "iteration 1100 / 2000: loss 2.615582\n",
      "iteration 1200 / 2000: loss 2.700929\n",
      "iteration 1300 / 2000: loss 2.645503\n",
      "iteration 1400 / 2000: loss 2.523799\n",
      "iteration 1500 / 2000: loss 2.508030\n",
      "iteration 1600 / 2000: loss 2.483122\n",
      "iteration 1700 / 2000: loss 2.498221\n",
      "iteration 1800 / 2000: loss 2.424016\n",
      "iteration 1900 / 2000: loss 2.436059\n",
      "iteration 0 / 2000: loss 13.551366\n",
      "iteration 100 / 2000: loss 10.194716\n",
      "iteration 200 / 2000: loss 9.796119\n",
      "iteration 300 / 2000: loss 9.236769\n",
      "iteration 400 / 2000: loss 8.821454\n",
      "iteration 500 / 2000: loss 8.589215\n",
      "iteration 600 / 2000: loss 8.584325\n",
      "iteration 700 / 2000: loss 8.063898\n",
      "iteration 800 / 2000: loss 7.854130\n",
      "iteration 900 / 2000: loss 7.512110\n",
      "iteration 1000 / 2000: loss 7.337599\n",
      "iteration 1100 / 2000: loss 7.315733\n",
      "iteration 1200 / 2000: loss 7.082316\n",
      "iteration 1300 / 2000: loss 6.982521\n",
      "iteration 1400 / 2000: loss 6.701693\n",
      "iteration 1500 / 2000: loss 6.676004\n",
      "iteration 1600 / 2000: loss 6.466048\n",
      "iteration 1700 / 2000: loss 6.400478\n",
      "iteration 1800 / 2000: loss 6.087575\n",
      "iteration 1900 / 2000: loss 6.161133\n",
      "iteration 0 / 2000: loss 19.086757\n",
      "iteration 100 / 2000: loss 16.479045\n",
      "iteration 200 / 2000: loss 15.186042\n",
      "iteration 300 / 2000: loss 14.317830\n",
      "iteration 400 / 2000: loss 13.153243\n",
      "iteration 500 / 2000: loss 12.641868\n",
      "iteration 600 / 2000: loss 12.169044\n",
      "iteration 700 / 2000: loss 11.420027\n",
      "iteration 800 / 2000: loss 11.102989\n",
      "iteration 900 / 2000: loss 10.371333\n",
      "iteration 1000 / 2000: loss 10.059344\n",
      "iteration 1100 / 2000: loss 9.709367\n",
      "iteration 1200 / 2000: loss 9.126674\n",
      "iteration 1300 / 2000: loss 8.753223\n",
      "iteration 1400 / 2000: loss 8.411536\n",
      "iteration 1500 / 2000: loss 7.890774\n",
      "iteration 1600 / 2000: loss 7.571338\n",
      "iteration 1700 / 2000: loss 7.104375\n",
      "iteration 1800 / 2000: loss 6.847622\n",
      "iteration 1900 / 2000: loss 6.572187\n",
      "iteration 0 / 2000: loss 25.290375\n",
      "iteration 100 / 2000: loss 22.458471\n",
      "iteration 200 / 2000: loss 20.373452\n",
      "iteration 300 / 2000: loss 18.857376\n",
      "iteration 400 / 2000: loss 17.223189\n",
      "iteration 500 / 2000: loss 16.232559\n",
      "iteration 600 / 2000: loss 14.899903\n",
      "iteration 700 / 2000: loss 13.824602\n",
      "iteration 800 / 2000: loss 12.869472\n",
      "iteration 900 / 2000: loss 11.851087\n",
      "iteration 1000 / 2000: loss 11.097066\n",
      "iteration 1100 / 2000: loss 10.406659\n",
      "iteration 1200 / 2000: loss 9.541386\n",
      "iteration 1300 / 2000: loss 8.942055\n",
      "iteration 1400 / 2000: loss 8.301903\n",
      "iteration 1500 / 2000: loss 7.821783\n",
      "iteration 1600 / 2000: loss 7.291373\n",
      "iteration 1700 / 2000: loss 7.042989\n",
      "iteration 1800 / 2000: loss 6.597516\n",
      "iteration 1900 / 2000: loss 6.144404\n",
      "iteration 0 / 2000: loss 33.262118\n",
      "iteration 100 / 2000: loss 27.865396\n",
      "iteration 200 / 2000: loss 24.747692\n",
      "iteration 300 / 2000: loss 22.241814\n",
      "iteration 400 / 2000: loss 19.890952\n",
      "iteration 500 / 2000: loss 17.897529\n",
      "iteration 600 / 2000: loss 16.123956\n",
      "iteration 700 / 2000: loss 14.711741\n",
      "iteration 800 / 2000: loss 13.352459\n",
      "iteration 900 / 2000: loss 12.080685\n",
      "iteration 1000 / 2000: loss 11.082856\n",
      "iteration 1100 / 2000: loss 10.065216\n",
      "iteration 1200 / 2000: loss 9.168999\n",
      "iteration 1300 / 2000: loss 8.468727\n",
      "iteration 1400 / 2000: loss 7.791012\n",
      "iteration 1500 / 2000: loss 7.225041\n",
      "iteration 1600 / 2000: loss 6.487751\n",
      "iteration 1700 / 2000: loss 6.109666\n",
      "iteration 1800 / 2000: loss 5.523917\n",
      "iteration 1900 / 2000: loss 5.252857\n",
      "iteration 0 / 2000: loss 39.720994\n",
      "iteration 100 / 2000: loss 32.742291\n",
      "iteration 200 / 2000: loss 28.190484\n",
      "iteration 300 / 2000: loss 24.884033\n",
      "iteration 400 / 2000: loss 21.884406\n",
      "iteration 500 / 2000: loss 19.146627\n",
      "iteration 600 / 2000: loss 16.991516\n",
      "iteration 700 / 2000: loss 15.022164\n",
      "iteration 800 / 2000: loss 13.351208\n",
      "iteration 900 / 2000: loss 12.012083\n",
      "iteration 1000 / 2000: loss 10.556426\n",
      "iteration 1100 / 2000: loss 9.380785\n",
      "iteration 1200 / 2000: loss 8.462978\n",
      "iteration 1300 / 2000: loss 7.656391\n",
      "iteration 1400 / 2000: loss 6.814840\n",
      "iteration 1500 / 2000: loss 6.227438\n",
      "iteration 1600 / 2000: loss 5.636090\n",
      "iteration 1700 / 2000: loss 5.286348\n",
      "iteration 1800 / 2000: loss 4.835314\n",
      "iteration 1900 / 2000: loss 4.416714\n",
      "iteration 0 / 2000: loss 45.753388\n",
      "iteration 100 / 2000: loss 36.983806\n",
      "iteration 200 / 2000: loss 31.405017\n",
      "iteration 300 / 2000: loss 26.945149\n",
      "iteration 400 / 2000: loss 23.245029\n",
      "iteration 500 / 2000: loss 19.885005\n",
      "iteration 600 / 2000: loss 17.241290\n",
      "iteration 700 / 2000: loss 14.757544\n",
      "iteration 800 / 2000: loss 12.917182\n",
      "iteration 900 / 2000: loss 11.269707\n",
      "iteration 1000 / 2000: loss 9.818447\n",
      "iteration 1100 / 2000: loss 8.591884\n",
      "iteration 1200 / 2000: loss 7.604829\n",
      "iteration 1300 / 2000: loss 6.766610\n",
      "iteration 1400 / 2000: loss 5.876790\n",
      "iteration 1500 / 2000: loss 5.315211\n",
      "iteration 1600 / 2000: loss 4.954323\n",
      "iteration 1700 / 2000: loss 4.332210\n",
      "iteration 1800 / 2000: loss 4.034855\n",
      "iteration 1900 / 2000: loss 3.636415\n",
      "iteration 0 / 2000: loss 54.060429\n",
      "iteration 100 / 2000: loss 42.928095\n",
      "iteration 200 / 2000: loss 35.593540\n",
      "iteration 300 / 2000: loss 29.432831\n",
      "iteration 400 / 2000: loss 24.507053\n",
      "iteration 500 / 2000: loss 20.594194\n",
      "iteration 600 / 2000: loss 17.308557\n",
      "iteration 700 / 2000: loss 14.587597\n",
      "iteration 800 / 2000: loss 12.363911\n",
      "iteration 900 / 2000: loss 10.483112\n",
      "iteration 1000 / 2000: loss 9.110355\n",
      "iteration 1100 / 2000: loss 7.823528\n",
      "iteration 1200 / 2000: loss 6.806749\n",
      "iteration 1300 / 2000: loss 5.993965\n",
      "iteration 1400 / 2000: loss 5.122020\n",
      "iteration 1500 / 2000: loss 4.620195\n",
      "iteration 1600 / 2000: loss 4.128822\n",
      "iteration 1700 / 2000: loss 3.854635\n",
      "iteration 1800 / 2000: loss 3.477421\n",
      "iteration 1900 / 2000: loss 3.164703\n",
      "iteration 0 / 2000: loss 61.552703\n",
      "iteration 100 / 2000: loss 47.729927\n",
      "iteration 200 / 2000: loss 38.483834\n",
      "iteration 300 / 2000: loss 31.139406\n",
      "iteration 400 / 2000: loss 25.452498\n",
      "iteration 500 / 2000: loss 20.765228\n",
      "iteration 600 / 2000: loss 16.950678\n",
      "iteration 700 / 2000: loss 13.999235\n",
      "iteration 800 / 2000: loss 11.789113\n",
      "iteration 900 / 2000: loss 9.750276\n",
      "iteration 1000 / 2000: loss 8.172724\n",
      "iteration 1100 / 2000: loss 7.042555\n",
      "iteration 1200 / 2000: loss 6.020544\n",
      "iteration 1300 / 2000: loss 5.088672\n",
      "iteration 1400 / 2000: loss 4.474779\n",
      "iteration 1500 / 2000: loss 4.000178\n",
      "iteration 1600 / 2000: loss 3.672215\n",
      "iteration 1700 / 2000: loss 3.197462\n",
      "iteration 1800 / 2000: loss 3.023760\n",
      "iteration 1900 / 2000: loss 2.562969\n",
      "iteration 0 / 2000: loss 66.597435\n",
      "iteration 100 / 2000: loss 51.064242\n",
      "iteration 200 / 2000: loss 40.108482\n",
      "iteration 300 / 2000: loss 32.017712\n",
      "iteration 400 / 2000: loss 25.471508\n",
      "iteration 500 / 2000: loss 20.309374\n",
      "iteration 600 / 2000: loss 16.308645\n",
      "iteration 700 / 2000: loss 13.095873\n",
      "iteration 800 / 2000: loss 10.735888\n",
      "iteration 900 / 2000: loss 8.800613\n",
      "iteration 1000 / 2000: loss 7.323594\n",
      "iteration 1100 / 2000: loss 6.205071\n",
      "iteration 1200 / 2000: loss 5.163267\n",
      "iteration 1300 / 2000: loss 4.479196\n",
      "iteration 1400 / 2000: loss 3.973421\n",
      "iteration 1500 / 2000: loss 3.575532\n",
      "iteration 1600 / 2000: loss 3.244547\n",
      "iteration 1700 / 2000: loss 2.848248\n",
      "iteration 1800 / 2000: loss 2.753436\n",
      "iteration 1900 / 2000: loss 2.466395\n",
      "iteration 0 / 2000: loss 5.512403\n",
      "iteration 100 / 2000: loss 3.062249\n",
      "iteration 200 / 2000: loss 3.046288\n",
      "iteration 300 / 2000: loss 2.770171\n",
      "iteration 400 / 2000: loss 2.786201\n",
      "iteration 500 / 2000: loss 2.517100\n",
      "iteration 600 / 2000: loss 2.594516\n",
      "iteration 700 / 2000: loss 2.459103\n",
      "iteration 800 / 2000: loss 2.578387\n",
      "iteration 900 / 2000: loss 2.314260\n",
      "iteration 1000 / 2000: loss 2.528494\n",
      "iteration 1100 / 2000: loss 2.410030\n",
      "iteration 1200 / 2000: loss 2.604146\n",
      "iteration 1300 / 2000: loss 2.442344\n",
      "iteration 1400 / 2000: loss 2.476695\n",
      "iteration 1500 / 2000: loss 2.276592\n",
      "iteration 1600 / 2000: loss 2.277534\n",
      "iteration 1700 / 2000: loss 2.144255\n",
      "iteration 1800 / 2000: loss 2.339605\n",
      "iteration 1900 / 2000: loss 2.461732\n",
      "iteration 0 / 2000: loss 13.039040\n",
      "iteration 100 / 2000: loss 9.495708\n",
      "iteration 200 / 2000: loss 8.897048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 300 / 2000: loss 8.577624\n",
      "iteration 400 / 2000: loss 8.231580\n",
      "iteration 500 / 2000: loss 7.761818\n",
      "iteration 600 / 2000: loss 7.468141\n",
      "iteration 700 / 2000: loss 7.128919\n",
      "iteration 800 / 2000: loss 6.804226\n",
      "iteration 900 / 2000: loss 6.654635\n",
      "iteration 1000 / 2000: loss 6.288651\n",
      "iteration 1100 / 2000: loss 5.976384\n",
      "iteration 1200 / 2000: loss 5.913434\n",
      "iteration 1300 / 2000: loss 5.807213\n",
      "iteration 1400 / 2000: loss 5.374128\n",
      "iteration 1500 / 2000: loss 5.265659\n",
      "iteration 1600 / 2000: loss 5.126599\n",
      "iteration 1700 / 2000: loss 4.952305\n",
      "iteration 1800 / 2000: loss 4.789484\n",
      "iteration 1900 / 2000: loss 4.689776\n",
      "iteration 0 / 2000: loss 19.773757\n",
      "iteration 100 / 2000: loss 15.666331\n",
      "iteration 200 / 2000: loss 14.172751\n",
      "iteration 300 / 2000: loss 12.965123\n",
      "iteration 400 / 2000: loss 11.837035\n",
      "iteration 500 / 2000: loss 10.818169\n",
      "iteration 600 / 2000: loss 10.156291\n",
      "iteration 700 / 2000: loss 9.256960\n",
      "iteration 800 / 2000: loss 8.643719\n",
      "iteration 900 / 2000: loss 8.167863\n",
      "iteration 1000 / 2000: loss 7.381223\n",
      "iteration 1100 / 2000: loss 7.098832\n",
      "iteration 1200 / 2000: loss 6.508574\n",
      "iteration 1300 / 2000: loss 6.195010\n",
      "iteration 1400 / 2000: loss 5.638150\n",
      "iteration 1500 / 2000: loss 5.290733\n",
      "iteration 1600 / 2000: loss 4.928263\n",
      "iteration 1700 / 2000: loss 4.803116\n",
      "iteration 1800 / 2000: loss 4.489340\n",
      "iteration 1900 / 2000: loss 4.317244\n",
      "iteration 0 / 2000: loss 26.560084\n",
      "iteration 100 / 2000: loss 20.936318\n",
      "iteration 200 / 2000: loss 18.023932\n",
      "iteration 300 / 2000: loss 15.797717\n",
      "iteration 400 / 2000: loss 14.140928\n",
      "iteration 500 / 2000: loss 12.726655\n",
      "iteration 600 / 2000: loss 11.193417\n",
      "iteration 700 / 2000: loss 9.881534\n",
      "iteration 800 / 2000: loss 8.966763\n",
      "iteration 900 / 2000: loss 8.002757\n",
      "iteration 1000 / 2000: loss 7.213663\n",
      "iteration 1100 / 2000: loss 6.414153\n",
      "iteration 1200 / 2000: loss 5.909616\n",
      "iteration 1300 / 2000: loss 5.437794\n",
      "iteration 1400 / 2000: loss 5.003684\n",
      "iteration 1500 / 2000: loss 4.531333\n",
      "iteration 1600 / 2000: loss 4.335630\n",
      "iteration 1700 / 2000: loss 4.010034\n",
      "iteration 1800 / 2000: loss 3.805079\n",
      "iteration 1900 / 2000: loss 3.552784\n",
      "iteration 0 / 2000: loss 33.214605\n",
      "iteration 100 / 2000: loss 25.490571\n",
      "iteration 200 / 2000: loss 21.326931\n",
      "iteration 300 / 2000: loss 18.151378\n",
      "iteration 400 / 2000: loss 15.328047\n",
      "iteration 500 / 2000: loss 12.992622\n",
      "iteration 600 / 2000: loss 11.166302\n",
      "iteration 700 / 2000: loss 9.569869\n",
      "iteration 800 / 2000: loss 8.562324\n",
      "iteration 900 / 2000: loss 7.237988\n",
      "iteration 1000 / 2000: loss 6.566017\n",
      "iteration 1100 / 2000: loss 5.718616\n",
      "iteration 1200 / 2000: loss 5.092685\n",
      "iteration 1300 / 2000: loss 4.642567\n",
      "iteration 1400 / 2000: loss 3.968122\n",
      "iteration 1500 / 2000: loss 3.727613\n",
      "iteration 1600 / 2000: loss 3.507457\n",
      "iteration 1700 / 2000: loss 3.135116\n",
      "iteration 1800 / 2000: loss 3.104612\n",
      "iteration 1900 / 2000: loss 2.719638\n",
      "iteration 0 / 2000: loss 39.856658\n",
      "iteration 100 / 2000: loss 30.284446\n",
      "iteration 200 / 2000: loss 24.147531\n",
      "iteration 300 / 2000: loss 19.551104\n",
      "iteration 400 / 2000: loss 16.200782\n",
      "iteration 500 / 2000: loss 13.162087\n",
      "iteration 600 / 2000: loss 10.977422\n",
      "iteration 700 / 2000: loss 9.253308\n",
      "iteration 800 / 2000: loss 7.670714\n",
      "iteration 900 / 2000: loss 6.510910\n",
      "iteration 1000 / 2000: loss 5.676362\n",
      "iteration 1100 / 2000: loss 4.684781\n",
      "iteration 1200 / 2000: loss 4.233353\n",
      "iteration 1300 / 2000: loss 3.768474\n",
      "iteration 1400 / 2000: loss 3.392283\n",
      "iteration 1500 / 2000: loss 3.125040\n",
      "iteration 1600 / 2000: loss 2.775017\n",
      "iteration 1700 / 2000: loss 2.689892\n",
      "iteration 1800 / 2000: loss 2.487584\n",
      "iteration 1900 / 2000: loss 2.470684\n",
      "iteration 0 / 2000: loss 46.941245\n",
      "iteration 100 / 2000: loss 34.200661\n",
      "iteration 200 / 2000: loss 26.318420\n",
      "iteration 300 / 2000: loss 20.577606\n",
      "iteration 400 / 2000: loss 16.176591\n",
      "iteration 500 / 2000: loss 12.822632\n",
      "iteration 600 / 2000: loss 10.233898\n",
      "iteration 700 / 2000: loss 8.203428\n",
      "iteration 800 / 2000: loss 6.743718\n",
      "iteration 900 / 2000: loss 5.666341\n",
      "iteration 1000 / 2000: loss 4.690095\n",
      "iteration 1100 / 2000: loss 4.069447\n",
      "iteration 1200 / 2000: loss 3.567098\n",
      "iteration 1300 / 2000: loss 3.158149\n",
      "iteration 1400 / 2000: loss 2.865584\n",
      "iteration 1500 / 2000: loss 2.607373\n",
      "iteration 1600 / 2000: loss 2.407741\n",
      "iteration 1700 / 2000: loss 2.313514\n",
      "iteration 1800 / 2000: loss 2.241467\n",
      "iteration 1900 / 2000: loss 2.030764\n",
      "iteration 0 / 2000: loss 54.359947\n",
      "iteration 100 / 2000: loss 37.848478\n",
      "iteration 200 / 2000: loss 27.996634\n",
      "iteration 300 / 2000: loss 20.948562\n",
      "iteration 400 / 2000: loss 16.012404\n",
      "iteration 500 / 2000: loss 12.090101\n",
      "iteration 600 / 2000: loss 9.400144\n",
      "iteration 700 / 2000: loss 7.341416\n",
      "iteration 800 / 2000: loss 5.928544\n",
      "iteration 900 / 2000: loss 4.856052\n",
      "iteration 1000 / 2000: loss 3.947974\n",
      "iteration 1100 / 2000: loss 3.449953\n",
      "iteration 1200 / 2000: loss 3.028322\n",
      "iteration 1300 / 2000: loss 2.856940\n",
      "iteration 1400 / 2000: loss 2.459322\n",
      "iteration 1500 / 2000: loss 2.262259\n",
      "iteration 1600 / 2000: loss 2.146913\n",
      "iteration 1700 / 2000: loss 2.067990\n",
      "iteration 1800 / 2000: loss 2.034003\n",
      "iteration 1900 / 2000: loss 1.968362\n",
      "iteration 0 / 2000: loss 60.033705\n",
      "iteration 100 / 2000: loss 40.908676\n",
      "iteration 200 / 2000: loss 29.100471\n",
      "iteration 300 / 2000: loss 21.123002\n",
      "iteration 400 / 2000: loss 15.326256\n",
      "iteration 500 / 2000: loss 11.256778\n",
      "iteration 600 / 2000: loss 8.495816\n",
      "iteration 700 / 2000: loss 6.526593\n",
      "iteration 800 / 2000: loss 5.107166\n",
      "iteration 900 / 2000: loss 4.134033\n",
      "iteration 1000 / 2000: loss 3.431622\n",
      "iteration 1100 / 2000: loss 3.097126\n",
      "iteration 1200 / 2000: loss 2.508935\n",
      "iteration 1300 / 2000: loss 2.421849\n",
      "iteration 1400 / 2000: loss 2.167425\n",
      "iteration 1500 / 2000: loss 2.212722\n",
      "iteration 1600 / 2000: loss 2.078553\n",
      "iteration 1700 / 2000: loss 1.984500\n",
      "iteration 1800 / 2000: loss 2.039063\n",
      "iteration 1900 / 2000: loss 1.921011\n",
      "iteration 0 / 2000: loss 67.277710\n",
      "iteration 100 / 2000: loss 43.929921\n",
      "iteration 200 / 2000: loss 29.749707\n",
      "iteration 300 / 2000: loss 20.641243\n",
      "iteration 400 / 2000: loss 14.560370\n",
      "iteration 500 / 2000: loss 10.236655\n",
      "iteration 600 / 2000: loss 7.595726\n",
      "iteration 700 / 2000: loss 5.628573\n",
      "iteration 800 / 2000: loss 4.497321\n",
      "iteration 900 / 2000: loss 3.661546\n",
      "iteration 1000 / 2000: loss 3.117910\n",
      "iteration 1100 / 2000: loss 2.668894\n",
      "iteration 1200 / 2000: loss 2.355380\n",
      "iteration 1300 / 2000: loss 2.154270\n",
      "iteration 1400 / 2000: loss 2.017164\n",
      "iteration 1500 / 2000: loss 2.114181\n",
      "iteration 1600 / 2000: loss 1.987486\n",
      "iteration 1700 / 2000: loss 1.985594\n",
      "iteration 1800 / 2000: loss 1.856689\n",
      "iteration 1900 / 2000: loss 1.928783\n",
      "iteration 0 / 2000: loss 6.215618\n",
      "iteration 100 / 2000: loss 3.163313\n",
      "iteration 200 / 2000: loss 2.679666\n",
      "iteration 300 / 2000: loss 2.650489\n",
      "iteration 400 / 2000: loss 2.561678\n",
      "iteration 500 / 2000: loss 2.431321\n",
      "iteration 600 / 2000: loss 2.488717\n",
      "iteration 700 / 2000: loss 2.453627\n",
      "iteration 800 / 2000: loss 2.601489\n",
      "iteration 900 / 2000: loss 2.464861\n",
      "iteration 1000 / 2000: loss 2.381379\n",
      "iteration 1100 / 2000: loss 2.302004\n",
      "iteration 1200 / 2000: loss 2.451175\n",
      "iteration 1300 / 2000: loss 2.251653\n",
      "iteration 1400 / 2000: loss 2.294553\n",
      "iteration 1500 / 2000: loss 2.246912\n",
      "iteration 1600 / 2000: loss 2.188154\n",
      "iteration 1700 / 2000: loss 2.369442\n",
      "iteration 1800 / 2000: loss 2.016457\n",
      "iteration 1900 / 2000: loss 2.222053\n",
      "iteration 0 / 2000: loss 11.997514\n",
      "iteration 100 / 2000: loss 9.317974\n",
      "iteration 200 / 2000: loss 8.782738\n",
      "iteration 300 / 2000: loss 8.147911\n",
      "iteration 400 / 2000: loss 7.550397\n",
      "iteration 500 / 2000: loss 7.173271\n",
      "iteration 600 / 2000: loss 6.762129\n",
      "iteration 700 / 2000: loss 6.519604\n",
      "iteration 800 / 2000: loss 6.068626\n",
      "iteration 900 / 2000: loss 5.912246\n",
      "iteration 1000 / 2000: loss 5.345588\n",
      "iteration 1100 / 2000: loss 5.143826\n",
      "iteration 1200 / 2000: loss 5.128920\n",
      "iteration 1300 / 2000: loss 5.060345\n",
      "iteration 1400 / 2000: loss 4.601328\n",
      "iteration 1500 / 2000: loss 4.365019\n",
      "iteration 1600 / 2000: loss 4.281082\n",
      "iteration 1700 / 2000: loss 4.055864\n",
      "iteration 1800 / 2000: loss 3.811707\n",
      "iteration 1900 / 2000: loss 3.848451\n",
      "iteration 0 / 2000: loss 19.943389\n",
      "iteration 100 / 2000: loss 15.061281\n",
      "iteration 200 / 2000: loss 13.240564\n",
      "iteration 300 / 2000: loss 11.626220\n",
      "iteration 400 / 2000: loss 10.416792\n",
      "iteration 500 / 2000: loss 9.532625\n",
      "iteration 600 / 2000: loss 8.617544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 700 / 2000: loss 7.651119\n",
      "iteration 800 / 2000: loss 6.882395\n",
      "iteration 900 / 2000: loss 6.381803\n",
      "iteration 1000 / 2000: loss 5.842484\n",
      "iteration 1100 / 2000: loss 5.396156\n",
      "iteration 1200 / 2000: loss 4.955017\n",
      "iteration 1300 / 2000: loss 4.512690\n",
      "iteration 1400 / 2000: loss 4.151321\n",
      "iteration 1500 / 2000: loss 3.981423\n",
      "iteration 1600 / 2000: loss 3.575578\n",
      "iteration 1700 / 2000: loss 3.532341\n",
      "iteration 1800 / 2000: loss 3.271221\n",
      "iteration 1900 / 2000: loss 3.045804\n",
      "iteration 0 / 2000: loss 25.799033\n",
      "iteration 100 / 2000: loss 19.852281\n",
      "iteration 200 / 2000: loss 16.579516\n",
      "iteration 300 / 2000: loss 14.021137\n",
      "iteration 400 / 2000: loss 11.852906\n",
      "iteration 500 / 2000: loss 10.089426\n",
      "iteration 600 / 2000: loss 8.571230\n",
      "iteration 700 / 2000: loss 7.511330\n",
      "iteration 800 / 2000: loss 6.611596\n",
      "iteration 900 / 2000: loss 5.665272\n",
      "iteration 1000 / 2000: loss 5.141129\n",
      "iteration 1100 / 2000: loss 4.423354\n",
      "iteration 1200 / 2000: loss 4.043002\n",
      "iteration 1300 / 2000: loss 3.672111\n",
      "iteration 1400 / 2000: loss 3.308166\n",
      "iteration 1500 / 2000: loss 3.033260\n",
      "iteration 1600 / 2000: loss 2.882907\n",
      "iteration 1700 / 2000: loss 2.642123\n",
      "iteration 1800 / 2000: loss 2.590511\n",
      "iteration 1900 / 2000: loss 2.443982\n",
      "iteration 0 / 2000: loss 32.844340\n",
      "iteration 100 / 2000: loss 23.936255\n",
      "iteration 200 / 2000: loss 18.804000\n",
      "iteration 300 / 2000: loss 15.184537\n",
      "iteration 400 / 2000: loss 12.015106\n",
      "iteration 500 / 2000: loss 9.782622\n",
      "iteration 600 / 2000: loss 8.188103\n",
      "iteration 700 / 2000: loss 6.628539\n",
      "iteration 800 / 2000: loss 5.493459\n",
      "iteration 900 / 2000: loss 4.817501\n",
      "iteration 1000 / 2000: loss 4.135051\n",
      "iteration 1100 / 2000: loss 3.612298\n",
      "iteration 1200 / 2000: loss 3.289772\n",
      "iteration 1300 / 2000: loss 2.904276\n",
      "iteration 1400 / 2000: loss 2.680727\n",
      "iteration 1500 / 2000: loss 2.461047\n",
      "iteration 1600 / 2000: loss 2.342585\n",
      "iteration 1700 / 2000: loss 2.214518\n",
      "iteration 1800 / 2000: loss 2.186428\n",
      "iteration 1900 / 2000: loss 1.963045\n",
      "iteration 0 / 2000: loss 39.691382\n",
      "iteration 100 / 2000: loss 27.840700\n",
      "iteration 200 / 2000: loss 20.864319\n",
      "iteration 300 / 2000: loss 15.562763\n",
      "iteration 400 / 2000: loss 11.850425\n",
      "iteration 500 / 2000: loss 9.283044\n",
      "iteration 600 / 2000: loss 7.158431\n",
      "iteration 700 / 2000: loss 5.819898\n",
      "iteration 800 / 2000: loss 4.730669\n",
      "iteration 900 / 2000: loss 3.965893\n",
      "iteration 1000 / 2000: loss 3.494291\n",
      "iteration 1100 / 2000: loss 2.955480\n",
      "iteration 1200 / 2000: loss 2.645358\n",
      "iteration 1300 / 2000: loss 2.404202\n",
      "iteration 1400 / 2000: loss 2.346203\n",
      "iteration 1500 / 2000: loss 2.231027\n",
      "iteration 1600 / 2000: loss 2.113011\n",
      "iteration 1700 / 2000: loss 1.981926\n",
      "iteration 1800 / 2000: loss 1.950025\n",
      "iteration 1900 / 2000: loss 2.022228\n",
      "iteration 0 / 2000: loss 46.428801\n",
      "iteration 100 / 2000: loss 30.972387\n",
      "iteration 200 / 2000: loss 21.896367\n",
      "iteration 300 / 2000: loss 15.655018\n",
      "iteration 400 / 2000: loss 11.203281\n",
      "iteration 500 / 2000: loss 8.400988\n",
      "iteration 600 / 2000: loss 6.436482\n",
      "iteration 700 / 2000: loss 4.943643\n",
      "iteration 800 / 2000: loss 3.956157\n",
      "iteration 900 / 2000: loss 3.353555\n",
      "iteration 1000 / 2000: loss 2.860341\n",
      "iteration 1100 / 2000: loss 2.643614\n",
      "iteration 1200 / 2000: loss 2.325060\n",
      "iteration 1300 / 2000: loss 2.233491\n",
      "iteration 1400 / 2000: loss 2.117753\n",
      "iteration 1500 / 2000: loss 1.994295\n",
      "iteration 1600 / 2000: loss 1.913158\n",
      "iteration 1700 / 2000: loss 1.921112\n",
      "iteration 1800 / 2000: loss 1.841871\n",
      "iteration 1900 / 2000: loss 1.992116\n",
      "iteration 0 / 2000: loss 53.491417\n",
      "iteration 100 / 2000: loss 33.127444\n",
      "iteration 200 / 2000: loss 22.197812\n",
      "iteration 300 / 2000: loss 15.072936\n",
      "iteration 400 / 2000: loss 10.463126\n",
      "iteration 500 / 2000: loss 7.444989\n",
      "iteration 600 / 2000: loss 5.544862\n",
      "iteration 700 / 2000: loss 4.237782\n",
      "iteration 800 / 2000: loss 3.312568\n",
      "iteration 900 / 2000: loss 2.869644\n",
      "iteration 1000 / 2000: loss 2.497971\n",
      "iteration 1100 / 2000: loss 2.262136\n",
      "iteration 1200 / 2000: loss 2.167953\n",
      "iteration 1300 / 2000: loss 2.002325\n",
      "iteration 1400 / 2000: loss 1.983655\n",
      "iteration 1500 / 2000: loss 2.023360\n",
      "iteration 1600 / 2000: loss 2.025858\n",
      "iteration 1700 / 2000: loss 1.864699\n",
      "iteration 1800 / 2000: loss 1.945480\n",
      "iteration 1900 / 2000: loss 1.837864\n",
      "iteration 0 / 2000: loss 61.459988\n",
      "iteration 100 / 2000: loss 36.281592\n",
      "iteration 200 / 2000: loss 22.683193\n",
      "iteration 300 / 2000: loss 14.450581\n",
      "iteration 400 / 2000: loss 9.681580\n",
      "iteration 500 / 2000: loss 6.597740\n",
      "iteration 600 / 2000: loss 4.769817\n",
      "iteration 700 / 2000: loss 3.689806\n",
      "iteration 800 / 2000: loss 3.010256\n",
      "iteration 900 / 2000: loss 2.507030\n",
      "iteration 1000 / 2000: loss 2.313464\n",
      "iteration 1100 / 2000: loss 2.104842\n",
      "iteration 1200 / 2000: loss 2.037921\n",
      "iteration 1300 / 2000: loss 1.931811\n",
      "iteration 1400 / 2000: loss 1.927556\n",
      "iteration 1500 / 2000: loss 1.924085\n",
      "iteration 1600 / 2000: loss 1.861521\n",
      "iteration 1700 / 2000: loss 1.873940\n",
      "iteration 1800 / 2000: loss 1.766973\n",
      "iteration 1900 / 2000: loss 1.901964\n",
      "iteration 0 / 2000: loss 66.958336\n",
      "iteration 100 / 2000: loss 38.013541\n",
      "iteration 200 / 2000: loss 22.459793\n",
      "iteration 300 / 2000: loss 13.720305\n",
      "iteration 400 / 2000: loss 8.693072\n",
      "iteration 500 / 2000: loss 5.891323\n",
      "iteration 600 / 2000: loss 4.147992\n",
      "iteration 700 / 2000: loss 3.235019\n",
      "iteration 800 / 2000: loss 2.643505\n",
      "iteration 900 / 2000: loss 2.299213\n",
      "iteration 1000 / 2000: loss 2.158944\n",
      "iteration 1100 / 2000: loss 2.145674\n",
      "iteration 1200 / 2000: loss 2.017267\n",
      "iteration 1300 / 2000: loss 1.963811\n",
      "iteration 1400 / 2000: loss 1.735091\n",
      "iteration 1500 / 2000: loss 1.839985\n",
      "iteration 1600 / 2000: loss 1.788222\n",
      "iteration 1700 / 2000: loss 1.839682\n",
      "iteration 1800 / 2000: loss 1.869546\n",
      "iteration 1900 / 2000: loss 1.910147\n",
      "iteration 0 / 2000: loss 5.055284\n",
      "iteration 100 / 2000: loss 3.325626\n",
      "iteration 200 / 2000: loss 2.799070\n",
      "iteration 300 / 2000: loss 2.815859\n",
      "iteration 400 / 2000: loss 2.700716\n",
      "iteration 500 / 2000: loss 2.564230\n",
      "iteration 600 / 2000: loss 2.492390\n",
      "iteration 700 / 2000: loss 2.653506\n",
      "iteration 800 / 2000: loss 2.456535\n",
      "iteration 900 / 2000: loss 2.408593\n",
      "iteration 1000 / 2000: loss 2.179491\n",
      "iteration 1100 / 2000: loss 2.293814\n",
      "iteration 1200 / 2000: loss 2.366663\n",
      "iteration 1300 / 2000: loss 2.191274\n",
      "iteration 1400 / 2000: loss 2.341431\n",
      "iteration 1500 / 2000: loss 2.101115\n",
      "iteration 1600 / 2000: loss 2.252036\n",
      "iteration 1700 / 2000: loss 2.270905\n",
      "iteration 1800 / 2000: loss 2.242901\n",
      "iteration 1900 / 2000: loss 2.171079\n",
      "iteration 0 / 2000: loss 13.374698\n",
      "iteration 100 / 2000: loss 9.332062\n",
      "iteration 200 / 2000: loss 8.461119\n",
      "iteration 300 / 2000: loss 7.996557\n",
      "iteration 400 / 2000: loss 7.144187\n",
      "iteration 500 / 2000: loss 6.589885\n",
      "iteration 600 / 2000: loss 6.372413\n",
      "iteration 700 / 2000: loss 5.965709\n",
      "iteration 800 / 2000: loss 5.481776\n",
      "iteration 900 / 2000: loss 5.152462\n",
      "iteration 1000 / 2000: loss 4.888797\n",
      "iteration 1100 / 2000: loss 4.751857\n",
      "iteration 1200 / 2000: loss 4.365643\n",
      "iteration 1300 / 2000: loss 4.344346\n",
      "iteration 1400 / 2000: loss 4.153510\n",
      "iteration 1500 / 2000: loss 3.927037\n",
      "iteration 1600 / 2000: loss 3.696523\n",
      "iteration 1700 / 2000: loss 3.628069\n",
      "iteration 1800 / 2000: loss 3.442936\n",
      "iteration 1900 / 2000: loss 3.259982\n",
      "iteration 0 / 2000: loss 19.643065\n",
      "iteration 100 / 2000: loss 14.425423\n",
      "iteration 200 / 2000: loss 12.316109\n",
      "iteration 300 / 2000: loss 10.424528\n",
      "iteration 400 / 2000: loss 9.239360\n",
      "iteration 500 / 2000: loss 8.023774\n",
      "iteration 600 / 2000: loss 7.223163\n",
      "iteration 700 / 2000: loss 6.415691\n",
      "iteration 800 / 2000: loss 5.604340\n",
      "iteration 900 / 2000: loss 5.050199\n",
      "iteration 1000 / 2000: loss 4.594760\n",
      "iteration 1100 / 2000: loss 4.077647\n",
      "iteration 1200 / 2000: loss 3.792147\n",
      "iteration 1300 / 2000: loss 3.401373\n",
      "iteration 1400 / 2000: loss 3.219830\n",
      "iteration 1500 / 2000: loss 3.059077\n",
      "iteration 1600 / 2000: loss 2.888226\n",
      "iteration 1700 / 2000: loss 2.650038\n",
      "iteration 1800 / 2000: loss 2.628893\n",
      "iteration 1900 / 2000: loss 2.410478\n",
      "iteration 0 / 2000: loss 26.338086\n",
      "iteration 100 / 2000: loss 18.739839\n",
      "iteration 200 / 2000: loss 14.977910\n",
      "iteration 300 / 2000: loss 12.039933\n",
      "iteration 400 / 2000: loss 9.757037\n",
      "iteration 500 / 2000: loss 7.956783\n",
      "iteration 600 / 2000: loss 6.773201\n",
      "iteration 700 / 2000: loss 5.614822\n",
      "iteration 800 / 2000: loss 4.720316\n",
      "iteration 900 / 2000: loss 4.242911\n",
      "iteration 1000 / 2000: loss 3.676735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1100 / 2000: loss 3.294091\n",
      "iteration 1200 / 2000: loss 2.980038\n",
      "iteration 1300 / 2000: loss 2.739574\n",
      "iteration 1400 / 2000: loss 2.413760\n",
      "iteration 1500 / 2000: loss 2.329731\n",
      "iteration 1600 / 2000: loss 2.232092\n",
      "iteration 1700 / 2000: loss 2.157155\n",
      "iteration 1800 / 2000: loss 2.019856\n",
      "iteration 1900 / 2000: loss 2.064546\n",
      "iteration 0 / 2000: loss 33.552500\n",
      "iteration 100 / 2000: loss 22.706910\n",
      "iteration 200 / 2000: loss 16.462888\n",
      "iteration 300 / 2000: loss 12.497335\n",
      "iteration 400 / 2000: loss 9.504994\n",
      "iteration 500 / 2000: loss 7.598102\n",
      "iteration 600 / 2000: loss 5.908594\n",
      "iteration 700 / 2000: loss 4.883054\n",
      "iteration 800 / 2000: loss 4.075047\n",
      "iteration 900 / 2000: loss 3.370788\n",
      "iteration 1000 / 2000: loss 2.957214\n",
      "iteration 1100 / 2000: loss 2.679259\n",
      "iteration 1200 / 2000: loss 2.494944\n",
      "iteration 1300 / 2000: loss 2.231628\n",
      "iteration 1400 / 2000: loss 2.134662\n",
      "iteration 1500 / 2000: loss 2.006882\n",
      "iteration 1600 / 2000: loss 2.050150\n",
      "iteration 1700 / 2000: loss 1.928311\n",
      "iteration 1800 / 2000: loss 2.042458\n",
      "iteration 1900 / 2000: loss 1.912070\n",
      "iteration 0 / 2000: loss 39.585906\n",
      "iteration 100 / 2000: loss 25.795973\n",
      "iteration 200 / 2000: loss 17.724633\n",
      "iteration 300 / 2000: loss 12.530837\n",
      "iteration 400 / 2000: loss 8.879740\n",
      "iteration 500 / 2000: loss 6.722702\n",
      "iteration 600 / 2000: loss 5.088276\n",
      "iteration 700 / 2000: loss 4.065008\n",
      "iteration 800 / 2000: loss 3.328103\n",
      "iteration 900 / 2000: loss 2.752791\n",
      "iteration 1000 / 2000: loss 2.467050\n",
      "iteration 1100 / 2000: loss 2.308001\n",
      "iteration 1200 / 2000: loss 2.188580\n",
      "iteration 1300 / 2000: loss 2.068372\n",
      "iteration 1400 / 2000: loss 2.101187\n",
      "iteration 1500 / 2000: loss 1.988765\n",
      "iteration 1600 / 2000: loss 1.851373\n",
      "iteration 1700 / 2000: loss 1.924793\n",
      "iteration 1800 / 2000: loss 1.883519\n",
      "iteration 1900 / 2000: loss 1.866621\n",
      "iteration 0 / 2000: loss 46.074621\n",
      "iteration 100 / 2000: loss 27.771226\n",
      "iteration 200 / 2000: loss 17.817491\n",
      "iteration 300 / 2000: loss 11.834834\n",
      "iteration 400 / 2000: loss 8.113407\n",
      "iteration 500 / 2000: loss 5.776783\n",
      "iteration 600 / 2000: loss 4.299800\n",
      "iteration 700 / 2000: loss 3.492602\n",
      "iteration 800 / 2000: loss 2.770437\n",
      "iteration 900 / 2000: loss 2.477258\n",
      "iteration 1000 / 2000: loss 2.197952\n",
      "iteration 1100 / 2000: loss 2.055085\n",
      "iteration 1200 / 2000: loss 2.030412\n",
      "iteration 1300 / 2000: loss 1.891467\n",
      "iteration 1400 / 2000: loss 2.037894\n",
      "iteration 1500 / 2000: loss 1.822557\n",
      "iteration 1600 / 2000: loss 1.800031\n",
      "iteration 1700 / 2000: loss 1.898343\n",
      "iteration 1800 / 2000: loss 1.848124\n",
      "iteration 1900 / 2000: loss 1.825951\n",
      "iteration 0 / 2000: loss 54.289177\n",
      "iteration 100 / 2000: loss 30.291268\n",
      "iteration 200 / 2000: loss 18.043271\n",
      "iteration 300 / 2000: loss 11.173170\n",
      "iteration 400 / 2000: loss 7.243950\n",
      "iteration 500 / 2000: loss 4.914017\n",
      "iteration 600 / 2000: loss 3.728126\n",
      "iteration 700 / 2000: loss 2.958404\n",
      "iteration 800 / 2000: loss 2.431626\n",
      "iteration 900 / 2000: loss 2.197360\n",
      "iteration 1000 / 2000: loss 2.062269\n",
      "iteration 1100 / 2000: loss 2.066736\n",
      "iteration 1200 / 2000: loss 1.917095\n",
      "iteration 1300 / 2000: loss 1.850010\n",
      "iteration 1400 / 2000: loss 1.881939\n",
      "iteration 1500 / 2000: loss 1.783495\n",
      "iteration 1600 / 2000: loss 1.984021\n",
      "iteration 1700 / 2000: loss 1.958971\n",
      "iteration 1800 / 2000: loss 1.835596\n",
      "iteration 1900 / 2000: loss 1.924376\n",
      "iteration 0 / 2000: loss 59.041120\n",
      "iteration 100 / 2000: loss 31.142287\n",
      "iteration 200 / 2000: loss 17.381831\n",
      "iteration 300 / 2000: loss 10.146074\n",
      "iteration 400 / 2000: loss 6.407244\n",
      "iteration 500 / 2000: loss 4.408375\n",
      "iteration 600 / 2000: loss 3.199109\n",
      "iteration 700 / 2000: loss 2.472154\n",
      "iteration 800 / 2000: loss 2.211916\n",
      "iteration 900 / 2000: loss 1.953333\n",
      "iteration 1000 / 2000: loss 1.998987\n",
      "iteration 1100 / 2000: loss 1.978132\n",
      "iteration 1200 / 2000: loss 1.877839\n",
      "iteration 1300 / 2000: loss 1.820801\n",
      "iteration 1400 / 2000: loss 1.848743\n",
      "iteration 1500 / 2000: loss 1.918970\n",
      "iteration 1600 / 2000: loss 1.894149\n",
      "iteration 1700 / 2000: loss 1.863735\n",
      "iteration 1800 / 2000: loss 1.860783\n",
      "iteration 1900 / 2000: loss 1.854748\n",
      "iteration 0 / 2000: loss 67.731714\n",
      "iteration 100 / 2000: loss 33.019619\n",
      "iteration 200 / 2000: loss 17.170212\n",
      "iteration 300 / 2000: loss 9.496400\n",
      "iteration 400 / 2000: loss 5.602149\n",
      "iteration 500 / 2000: loss 3.731516\n",
      "iteration 600 / 2000: loss 2.779417\n",
      "iteration 700 / 2000: loss 2.385929\n",
      "iteration 800 / 2000: loss 2.115021\n",
      "iteration 900 / 2000: loss 2.150700\n",
      "iteration 1000 / 2000: loss 1.881118\n",
      "iteration 1100 / 2000: loss 1.963311\n",
      "iteration 1200 / 2000: loss 2.015074\n",
      "iteration 1300 / 2000: loss 1.858305\n",
      "iteration 1400 / 2000: loss 1.853418\n",
      "iteration 1500 / 2000: loss 1.902954\n",
      "iteration 1600 / 2000: loss 1.936692\n",
      "iteration 1700 / 2000: loss 1.933233\n",
      "iteration 1800 / 2000: loss 1.793502\n",
      "iteration 1900 / 2000: loss 1.829687\n",
      "iteration 0 / 2000: loss 5.163286\n",
      "iteration 100 / 2000: loss 3.220352\n",
      "iteration 200 / 2000: loss 2.863774\n",
      "iteration 300 / 2000: loss 2.563492\n",
      "iteration 400 / 2000: loss 2.187100\n",
      "iteration 500 / 2000: loss 2.381866\n",
      "iteration 600 / 2000: loss 2.195477\n",
      "iteration 700 / 2000: loss 2.262573\n",
      "iteration 800 / 2000: loss 2.316248\n",
      "iteration 900 / 2000: loss 2.312267\n",
      "iteration 1000 / 2000: loss 2.169374\n",
      "iteration 1100 / 2000: loss 2.221738\n",
      "iteration 1200 / 2000: loss 2.303459\n",
      "iteration 1300 / 2000: loss 2.216205\n",
      "iteration 1400 / 2000: loss 2.187018\n",
      "iteration 1500 / 2000: loss 2.126676\n",
      "iteration 1600 / 2000: loss 2.158137\n",
      "iteration 1700 / 2000: loss 1.946147\n",
      "iteration 1800 / 2000: loss 2.234665\n",
      "iteration 1900 / 2000: loss 2.071910\n",
      "iteration 0 / 2000: loss 12.690722\n",
      "iteration 100 / 2000: loss 9.348868\n",
      "iteration 200 / 2000: loss 8.074700\n",
      "iteration 300 / 2000: loss 7.432859\n",
      "iteration 400 / 2000: loss 6.756920\n",
      "iteration 500 / 2000: loss 6.271891\n",
      "iteration 600 / 2000: loss 5.790397\n",
      "iteration 700 / 2000: loss 5.271116\n",
      "iteration 800 / 2000: loss 4.979503\n",
      "iteration 900 / 2000: loss 4.670213\n",
      "iteration 1000 / 2000: loss 4.411099\n",
      "iteration 1100 / 2000: loss 4.051899\n",
      "iteration 1200 / 2000: loss 3.720459\n",
      "iteration 1300 / 2000: loss 3.740126\n",
      "iteration 1400 / 2000: loss 3.477548\n",
      "iteration 1500 / 2000: loss 3.308749\n",
      "iteration 1600 / 2000: loss 3.183762\n",
      "iteration 1700 / 2000: loss 3.053348\n",
      "iteration 1800 / 2000: loss 2.855192\n",
      "iteration 1900 / 2000: loss 2.805168\n",
      "iteration 0 / 2000: loss 18.747710\n",
      "iteration 100 / 2000: loss 13.962532\n",
      "iteration 200 / 2000: loss 11.502914\n",
      "iteration 300 / 2000: loss 9.900328\n",
      "iteration 400 / 2000: loss 8.123565\n",
      "iteration 500 / 2000: loss 7.051266\n",
      "iteration 600 / 2000: loss 6.132276\n",
      "iteration 700 / 2000: loss 5.283123\n",
      "iteration 800 / 2000: loss 4.709605\n",
      "iteration 900 / 2000: loss 4.138590\n",
      "iteration 1000 / 2000: loss 3.799709\n",
      "iteration 1100 / 2000: loss 3.358172\n",
      "iteration 1200 / 2000: loss 3.025350\n",
      "iteration 1300 / 2000: loss 2.816033\n",
      "iteration 1400 / 2000: loss 2.635043\n",
      "iteration 1500 / 2000: loss 2.368948\n",
      "iteration 1600 / 2000: loss 2.366280\n",
      "iteration 1700 / 2000: loss 2.356625\n",
      "iteration 1800 / 2000: loss 2.243798\n",
      "iteration 1900 / 2000: loss 2.013990\n",
      "iteration 0 / 2000: loss 25.949057\n",
      "iteration 100 / 2000: loss 17.453252\n",
      "iteration 200 / 2000: loss 13.387572\n",
      "iteration 300 / 2000: loss 10.501553\n",
      "iteration 400 / 2000: loss 8.129228\n",
      "iteration 500 / 2000: loss 6.590211\n",
      "iteration 600 / 2000: loss 5.382036\n",
      "iteration 700 / 2000: loss 4.587586\n",
      "iteration 800 / 2000: loss 3.702810\n",
      "iteration 900 / 2000: loss 3.224417\n",
      "iteration 1000 / 2000: loss 2.913456\n",
      "iteration 1100 / 2000: loss 2.568110\n",
      "iteration 1200 / 2000: loss 2.485436\n",
      "iteration 1300 / 2000: loss 2.342267\n",
      "iteration 1400 / 2000: loss 2.023695\n",
      "iteration 1500 / 2000: loss 2.079043\n",
      "iteration 1600 / 2000: loss 2.089949\n",
      "iteration 1700 / 2000: loss 1.948629\n",
      "iteration 1800 / 2000: loss 1.956187\n",
      "iteration 1900 / 2000: loss 1.866499\n",
      "iteration 0 / 2000: loss 33.675133\n",
      "iteration 100 / 2000: loss 20.942013\n",
      "iteration 200 / 2000: loss 14.713513\n",
      "iteration 300 / 2000: loss 10.469735\n",
      "iteration 400 / 2000: loss 7.704237\n",
      "iteration 500 / 2000: loss 5.827842\n",
      "iteration 600 / 2000: loss 4.617509\n",
      "iteration 700 / 2000: loss 3.802646\n",
      "iteration 800 / 2000: loss 3.142582\n",
      "iteration 900 / 2000: loss 2.740926\n",
      "iteration 1000 / 2000: loss 2.404230\n",
      "iteration 1100 / 2000: loss 2.212607\n",
      "iteration 1200 / 2000: loss 2.036003\n",
      "iteration 1300 / 2000: loss 1.997246\n",
      "iteration 1400 / 2000: loss 1.988226\n",
      "iteration 1500 / 2000: loss 1.928061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1600 / 2000: loss 1.906321\n",
      "iteration 1700 / 2000: loss 1.763787\n",
      "iteration 1800 / 2000: loss 1.909218\n",
      "iteration 1900 / 2000: loss 1.942406\n",
      "iteration 0 / 2000: loss 40.248700\n",
      "iteration 100 / 2000: loss 23.992837\n",
      "iteration 200 / 2000: loss 15.353731\n",
      "iteration 300 / 2000: loss 10.068880\n",
      "iteration 400 / 2000: loss 6.953034\n",
      "iteration 500 / 2000: loss 4.962031\n",
      "iteration 600 / 2000: loss 3.797853\n",
      "iteration 700 / 2000: loss 2.913432\n",
      "iteration 800 / 2000: loss 2.583103\n",
      "iteration 900 / 2000: loss 2.273402\n",
      "iteration 1000 / 2000: loss 2.120560\n",
      "iteration 1100 / 2000: loss 2.059986\n",
      "iteration 1200 / 2000: loss 1.824247\n",
      "iteration 1300 / 2000: loss 1.892151\n",
      "iteration 1400 / 2000: loss 1.904821\n",
      "iteration 1500 / 2000: loss 1.940825\n",
      "iteration 1600 / 2000: loss 1.813536\n",
      "iteration 1700 / 2000: loss 1.861014\n",
      "iteration 1800 / 2000: loss 1.655049\n",
      "iteration 1900 / 2000: loss 1.850211\n",
      "iteration 0 / 2000: loss 47.102473\n",
      "iteration 100 / 2000: loss 25.740444\n",
      "iteration 200 / 2000: loss 15.216172\n",
      "iteration 300 / 2000: loss 9.209345\n",
      "iteration 400 / 2000: loss 6.134585\n",
      "iteration 500 / 2000: loss 4.284547\n",
      "iteration 600 / 2000: loss 3.182002\n",
      "iteration 700 / 2000: loss 2.655927\n",
      "iteration 800 / 2000: loss 2.232794\n",
      "iteration 900 / 2000: loss 2.096260\n",
      "iteration 1000 / 2000: loss 1.935670\n",
      "iteration 1100 / 2000: loss 2.033506\n",
      "iteration 1200 / 2000: loss 1.909941\n",
      "iteration 1300 / 2000: loss 1.921071\n",
      "iteration 1400 / 2000: loss 1.926952\n",
      "iteration 1500 / 2000: loss 1.835517\n",
      "iteration 1600 / 2000: loss 1.831671\n",
      "iteration 1700 / 2000: loss 1.815971\n",
      "iteration 1800 / 2000: loss 1.926972\n",
      "iteration 1900 / 2000: loss 1.946437\n",
      "iteration 0 / 2000: loss 53.215478\n",
      "iteration 100 / 2000: loss 26.950986\n",
      "iteration 200 / 2000: loss 14.706361\n",
      "iteration 300 / 2000: loss 8.439422\n",
      "iteration 400 / 2000: loss 5.080708\n",
      "iteration 500 / 2000: loss 3.646929\n",
      "iteration 600 / 2000: loss 2.795873\n",
      "iteration 700 / 2000: loss 2.312270\n",
      "iteration 800 / 2000: loss 2.095676\n",
      "iteration 900 / 2000: loss 2.038388\n",
      "iteration 1000 / 2000: loss 1.920917\n",
      "iteration 1100 / 2000: loss 1.871405\n",
      "iteration 1200 / 2000: loss 1.958973\n",
      "iteration 1300 / 2000: loss 1.859632\n",
      "iteration 1400 / 2000: loss 1.845999\n",
      "iteration 1500 / 2000: loss 1.848621\n",
      "iteration 1600 / 2000: loss 1.817122\n",
      "iteration 1700 / 2000: loss 1.815948\n",
      "iteration 1800 / 2000: loss 1.752089\n",
      "iteration 1900 / 2000: loss 1.929496\n",
      "iteration 0 / 2000: loss 59.270655\n",
      "iteration 100 / 2000: loss 27.493375\n",
      "iteration 200 / 2000: loss 13.657979\n",
      "iteration 300 / 2000: loss 7.421705\n",
      "iteration 400 / 2000: loss 4.551791\n",
      "iteration 500 / 2000: loss 3.125807\n",
      "iteration 600 / 2000: loss 2.519782\n",
      "iteration 700 / 2000: loss 2.173585\n",
      "iteration 800 / 2000: loss 1.974924\n",
      "iteration 900 / 2000: loss 1.933210\n",
      "iteration 1000 / 2000: loss 1.871452\n",
      "iteration 1100 / 2000: loss 2.019734\n",
      "iteration 1200 / 2000: loss 1.843733\n",
      "iteration 1300 / 2000: loss 1.832710\n",
      "iteration 1400 / 2000: loss 1.878193\n",
      "iteration 1500 / 2000: loss 1.760705\n",
      "iteration 1600 / 2000: loss 1.835095\n",
      "iteration 1700 / 2000: loss 1.791403\n",
      "iteration 1800 / 2000: loss 1.881599\n",
      "iteration 1900 / 2000: loss 1.845631\n",
      "iteration 0 / 2000: loss 66.889607\n",
      "iteration 100 / 2000: loss 28.179244\n",
      "iteration 200 / 2000: loss 13.050325\n",
      "iteration 300 / 2000: loss 6.706338\n",
      "iteration 400 / 2000: loss 3.927496\n",
      "iteration 500 / 2000: loss 2.778338\n",
      "iteration 600 / 2000: loss 2.339801\n",
      "iteration 700 / 2000: loss 2.085473\n",
      "iteration 800 / 2000: loss 2.011786\n",
      "iteration 900 / 2000: loss 1.860166\n",
      "iteration 1000 / 2000: loss 1.993589\n",
      "iteration 1100 / 2000: loss 1.882946\n",
      "iteration 1200 / 2000: loss 1.843843\n",
      "iteration 1300 / 2000: loss 1.835045\n",
      "iteration 1400 / 2000: loss 1.932623\n",
      "iteration 1500 / 2000: loss 1.943728\n",
      "iteration 1600 / 2000: loss 1.862142\n",
      "iteration 1700 / 2000: loss 1.965952\n",
      "iteration 1800 / 2000: loss 1.860341\n",
      "iteration 1900 / 2000: loss 1.924253\n",
      "iteration 0 / 2000: loss 6.567241\n",
      "iteration 100 / 2000: loss 3.174713\n",
      "iteration 200 / 2000: loss 2.625290\n",
      "iteration 300 / 2000: loss 2.540484\n",
      "iteration 400 / 2000: loss 2.535537\n",
      "iteration 500 / 2000: loss 2.431573\n",
      "iteration 600 / 2000: loss 2.377624\n",
      "iteration 700 / 2000: loss 2.284219\n",
      "iteration 800 / 2000: loss 2.235184\n",
      "iteration 900 / 2000: loss 2.264230\n",
      "iteration 1000 / 2000: loss 2.349147\n",
      "iteration 1100 / 2000: loss 2.334944\n",
      "iteration 1200 / 2000: loss 1.927679\n",
      "iteration 1300 / 2000: loss 2.266404\n",
      "iteration 1400 / 2000: loss 2.485328\n",
      "iteration 1500 / 2000: loss 2.046088\n",
      "iteration 1600 / 2000: loss 2.139388\n",
      "iteration 1700 / 2000: loss 2.041464\n",
      "iteration 1800 / 2000: loss 2.128344\n",
      "iteration 1900 / 2000: loss 2.131526\n",
      "iteration 0 / 2000: loss 11.986307\n",
      "iteration 100 / 2000: loss 8.975605\n",
      "iteration 200 / 2000: loss 7.643015\n",
      "iteration 300 / 2000: loss 7.185999\n",
      "iteration 400 / 2000: loss 6.546289\n",
      "iteration 500 / 2000: loss 5.719523\n",
      "iteration 600 / 2000: loss 5.323861\n",
      "iteration 700 / 2000: loss 4.838132\n",
      "iteration 800 / 2000: loss 4.519997\n",
      "iteration 900 / 2000: loss 4.288776\n",
      "iteration 1000 / 2000: loss 3.877030\n",
      "iteration 1100 / 2000: loss 3.741972\n",
      "iteration 1200 / 2000: loss 3.449304\n",
      "iteration 1300 / 2000: loss 3.190632\n",
      "iteration 1400 / 2000: loss 3.144952\n",
      "iteration 1500 / 2000: loss 2.897508\n",
      "iteration 1600 / 2000: loss 2.854227\n",
      "iteration 1700 / 2000: loss 2.767608\n",
      "iteration 1800 / 2000: loss 2.536557\n",
      "iteration 1900 / 2000: loss 2.565449\n",
      "iteration 0 / 2000: loss 19.830918\n",
      "iteration 100 / 2000: loss 13.585394\n",
      "iteration 200 / 2000: loss 10.988617\n",
      "iteration 300 / 2000: loss 9.036155\n",
      "iteration 400 / 2000: loss 7.546712\n",
      "iteration 500 / 2000: loss 6.274531\n",
      "iteration 600 / 2000: loss 5.351222\n",
      "iteration 700 / 2000: loss 4.577354\n",
      "iteration 800 / 2000: loss 4.052399\n",
      "iteration 900 / 2000: loss 3.667271\n",
      "iteration 1000 / 2000: loss 3.124465\n",
      "iteration 1100 / 2000: loss 2.958589\n",
      "iteration 1200 / 2000: loss 2.644659\n",
      "iteration 1300 / 2000: loss 2.382031\n",
      "iteration 1400 / 2000: loss 2.384600\n",
      "iteration 1500 / 2000: loss 2.165785\n",
      "iteration 1600 / 2000: loss 2.148528\n",
      "iteration 1700 / 2000: loss 2.118950\n",
      "iteration 1800 / 2000: loss 1.963080\n",
      "iteration 1900 / 2000: loss 2.007043\n",
      "iteration 0 / 2000: loss 26.195425\n",
      "iteration 100 / 2000: loss 16.937161\n",
      "iteration 200 / 2000: loss 12.294087\n",
      "iteration 300 / 2000: loss 9.277120\n",
      "iteration 400 / 2000: loss 7.078063\n",
      "iteration 500 / 2000: loss 5.598384\n",
      "iteration 600 / 2000: loss 4.434703\n",
      "iteration 700 / 2000: loss 3.767841\n",
      "iteration 800 / 2000: loss 3.143728\n",
      "iteration 900 / 2000: loss 2.782321\n",
      "iteration 1000 / 2000: loss 2.537736\n",
      "iteration 1100 / 2000: loss 2.243663\n",
      "iteration 1200 / 2000: loss 2.241694\n",
      "iteration 1300 / 2000: loss 2.105527\n",
      "iteration 1400 / 2000: loss 1.998781\n",
      "iteration 1500 / 2000: loss 1.942536\n",
      "iteration 1600 / 2000: loss 2.014284\n",
      "iteration 1700 / 2000: loss 1.929492\n",
      "iteration 1800 / 2000: loss 1.693419\n",
      "iteration 1900 / 2000: loss 1.822314\n",
      "iteration 0 / 2000: loss 32.931216\n",
      "iteration 100 / 2000: loss 19.555048\n",
      "iteration 200 / 2000: loss 13.187339\n",
      "iteration 300 / 2000: loss 8.867769\n",
      "iteration 400 / 2000: loss 6.417764\n",
      "iteration 500 / 2000: loss 4.672620\n",
      "iteration 600 / 2000: loss 3.594232\n",
      "iteration 700 / 2000: loss 2.872666\n",
      "iteration 800 / 2000: loss 2.605191\n",
      "iteration 900 / 2000: loss 2.379527\n",
      "iteration 1000 / 2000: loss 2.154198\n",
      "iteration 1100 / 2000: loss 2.076960\n",
      "iteration 1200 / 2000: loss 1.998921\n",
      "iteration 1300 / 2000: loss 1.859381\n",
      "iteration 1400 / 2000: loss 1.853354\n",
      "iteration 1500 / 2000: loss 1.834422\n",
      "iteration 1600 / 2000: loss 1.898617\n",
      "iteration 1700 / 2000: loss 1.804943\n",
      "iteration 1800 / 2000: loss 1.810338\n",
      "iteration 1900 / 2000: loss 1.826776\n",
      "iteration 0 / 2000: loss 38.921920\n",
      "iteration 100 / 2000: loss 21.445456\n",
      "iteration 200 / 2000: loss 12.813820\n",
      "iteration 300 / 2000: loss 7.973817\n",
      "iteration 400 / 2000: loss 5.424371\n",
      "iteration 500 / 2000: loss 3.792138\n",
      "iteration 600 / 2000: loss 2.782368\n",
      "iteration 700 / 2000: loss 2.442645\n",
      "iteration 800 / 2000: loss 2.150821\n",
      "iteration 900 / 2000: loss 2.028313\n",
      "iteration 1000 / 2000: loss 1.945458\n",
      "iteration 1100 / 2000: loss 1.929689\n",
      "iteration 1200 / 2000: loss 1.832906\n",
      "iteration 1300 / 2000: loss 1.820965\n",
      "iteration 1400 / 2000: loss 1.975991\n",
      "iteration 1500 / 2000: loss 1.798713\n",
      "iteration 1600 / 2000: loss 1.833261\n",
      "iteration 1700 / 2000: loss 1.827431\n",
      "iteration 1800 / 2000: loss 1.808304\n",
      "iteration 1900 / 2000: loss 1.819544\n",
      "iteration 0 / 2000: loss 45.930793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 2000: loss 23.020640\n",
      "iteration 200 / 2000: loss 12.447192\n",
      "iteration 300 / 2000: loss 7.076539\n",
      "iteration 400 / 2000: loss 4.627965\n",
      "iteration 500 / 2000: loss 3.212349\n",
      "iteration 600 / 2000: loss 2.562936\n",
      "iteration 700 / 2000: loss 2.143536\n",
      "iteration 800 / 2000: loss 2.043267\n",
      "iteration 900 / 2000: loss 2.022685\n",
      "iteration 1000 / 2000: loss 1.868453\n",
      "iteration 1100 / 2000: loss 1.879488\n",
      "iteration 1200 / 2000: loss 1.825327\n",
      "iteration 1300 / 2000: loss 1.917163\n",
      "iteration 1400 / 2000: loss 1.948975\n",
      "iteration 1500 / 2000: loss 1.869106\n",
      "iteration 1600 / 2000: loss 1.840073\n",
      "iteration 1700 / 2000: loss 1.695129\n",
      "iteration 1800 / 2000: loss 1.847010\n",
      "iteration 1900 / 2000: loss 1.863398\n",
      "iteration 0 / 2000: loss 54.432997\n",
      "iteration 100 / 2000: loss 24.393848\n",
      "iteration 200 / 2000: loss 12.144131\n",
      "iteration 300 / 2000: loss 6.416774\n",
      "iteration 400 / 2000: loss 3.907626\n",
      "iteration 500 / 2000: loss 2.800033\n",
      "iteration 600 / 2000: loss 2.447779\n",
      "iteration 700 / 2000: loss 1.948158\n",
      "iteration 800 / 2000: loss 1.901746\n",
      "iteration 900 / 2000: loss 1.872288\n",
      "iteration 1000 / 2000: loss 1.834349\n",
      "iteration 1100 / 2000: loss 1.925395\n",
      "iteration 1200 / 2000: loss 1.839682\n",
      "iteration 1300 / 2000: loss 1.828516\n",
      "iteration 1400 / 2000: loss 1.842489\n",
      "iteration 1500 / 2000: loss 1.821741\n",
      "iteration 1600 / 2000: loss 1.951280\n",
      "iteration 1700 / 2000: loss 1.806927\n",
      "iteration 1800 / 2000: loss 1.890400\n",
      "iteration 1900 / 2000: loss 1.811350\n",
      "iteration 0 / 2000: loss 60.014290\n",
      "iteration 100 / 2000: loss 24.112446\n",
      "iteration 200 / 2000: loss 10.906564\n",
      "iteration 300 / 2000: loss 5.423470\n",
      "iteration 400 / 2000: loss 3.392589\n",
      "iteration 500 / 2000: loss 2.424206\n",
      "iteration 600 / 2000: loss 2.112442\n",
      "iteration 700 / 2000: loss 1.940550\n",
      "iteration 800 / 2000: loss 1.850094\n",
      "iteration 900 / 2000: loss 1.906664\n",
      "iteration 1000 / 2000: loss 1.988863\n",
      "iteration 1100 / 2000: loss 1.973335\n",
      "iteration 1200 / 2000: loss 1.948863\n",
      "iteration 1300 / 2000: loss 1.872067\n",
      "iteration 1400 / 2000: loss 1.915027\n",
      "iteration 1500 / 2000: loss 1.934165\n",
      "iteration 1600 / 2000: loss 1.803941\n",
      "iteration 1700 / 2000: loss 1.919479\n",
      "iteration 1800 / 2000: loss 1.874333\n",
      "iteration 1900 / 2000: loss 1.825397\n",
      "iteration 0 / 2000: loss 67.414198\n",
      "iteration 100 / 2000: loss 24.418738\n",
      "iteration 200 / 2000: loss 10.072477\n",
      "iteration 300 / 2000: loss 4.860944\n",
      "iteration 400 / 2000: loss 3.036919\n",
      "iteration 500 / 2000: loss 2.261517\n",
      "iteration 600 / 2000: loss 2.037603\n",
      "iteration 700 / 2000: loss 1.924508\n",
      "iteration 800 / 2000: loss 1.917201\n",
      "iteration 900 / 2000: loss 1.875645\n",
      "iteration 1000 / 2000: loss 1.935430\n",
      "iteration 1100 / 2000: loss 1.949470\n",
      "iteration 1200 / 2000: loss 1.941300\n",
      "iteration 1300 / 2000: loss 1.896941\n",
      "iteration 1400 / 2000: loss 1.799109\n",
      "iteration 1500 / 2000: loss 1.897138\n",
      "iteration 1600 / 2000: loss 1.912691\n",
      "iteration 1700 / 2000: loss 1.910018\n",
      "iteration 1800 / 2000: loss 1.976965\n",
      "iteration 1900 / 2000: loss 1.965087\n",
      "iteration 0 / 2000: loss 5.363091\n",
      "iteration 100 / 2000: loss 2.871818\n",
      "iteration 200 / 2000: loss 2.680432\n",
      "iteration 300 / 2000: loss 2.573498\n",
      "iteration 400 / 2000: loss 2.347882\n",
      "iteration 500 / 2000: loss 2.497209\n",
      "iteration 600 / 2000: loss 2.207811\n",
      "iteration 700 / 2000: loss 2.292226\n",
      "iteration 800 / 2000: loss 2.317079\n",
      "iteration 900 / 2000: loss 2.071777\n",
      "iteration 1000 / 2000: loss 2.197262\n",
      "iteration 1100 / 2000: loss 2.248611\n",
      "iteration 1200 / 2000: loss 2.230124\n",
      "iteration 1300 / 2000: loss 2.136800\n",
      "iteration 1400 / 2000: loss 2.097749\n",
      "iteration 1500 / 2000: loss 2.035856\n",
      "iteration 1600 / 2000: loss 2.126545\n",
      "iteration 1700 / 2000: loss 2.119903\n",
      "iteration 1800 / 2000: loss 2.025976\n",
      "iteration 1900 / 2000: loss 2.055596\n",
      "iteration 0 / 2000: loss 12.959064\n",
      "iteration 100 / 2000: loss 8.616701\n",
      "iteration 200 / 2000: loss 7.555112\n",
      "iteration 300 / 2000: loss 6.631464\n",
      "iteration 400 / 2000: loss 5.890443\n",
      "iteration 500 / 2000: loss 5.365717\n",
      "iteration 600 / 2000: loss 4.986077\n",
      "iteration 700 / 2000: loss 4.435340\n",
      "iteration 800 / 2000: loss 4.096745\n",
      "iteration 900 / 2000: loss 3.814698\n",
      "iteration 1000 / 2000: loss 3.547501\n",
      "iteration 1100 / 2000: loss 3.238884\n",
      "iteration 1200 / 2000: loss 3.219192\n",
      "iteration 1300 / 2000: loss 2.961409\n",
      "iteration 1400 / 2000: loss 2.773058\n",
      "iteration 1500 / 2000: loss 2.750615\n",
      "iteration 1600 / 2000: loss 2.559344\n",
      "iteration 1700 / 2000: loss 2.419809\n",
      "iteration 1800 / 2000: loss 2.339348\n",
      "iteration 1900 / 2000: loss 2.219824\n",
      "iteration 0 / 2000: loss 19.456743\n",
      "iteration 100 / 2000: loss 12.980387\n",
      "iteration 200 / 2000: loss 10.191794\n",
      "iteration 300 / 2000: loss 8.156316\n",
      "iteration 400 / 2000: loss 6.585364\n",
      "iteration 500 / 2000: loss 5.544766\n",
      "iteration 600 / 2000: loss 4.688503\n",
      "iteration 700 / 2000: loss 3.905415\n",
      "iteration 800 / 2000: loss 3.437792\n",
      "iteration 900 / 2000: loss 3.126566\n",
      "iteration 1000 / 2000: loss 2.766199\n",
      "iteration 1100 / 2000: loss 2.480982\n",
      "iteration 1200 / 2000: loss 2.456487\n",
      "iteration 1300 / 2000: loss 2.198345\n",
      "iteration 1400 / 2000: loss 2.103163\n",
      "iteration 1500 / 2000: loss 2.083873\n",
      "iteration 1600 / 2000: loss 1.913407\n",
      "iteration 1700 / 2000: loss 1.891024\n",
      "iteration 1800 / 2000: loss 1.884815\n",
      "iteration 1900 / 2000: loss 1.969724\n",
      "iteration 0 / 2000: loss 25.944503\n",
      "iteration 100 / 2000: loss 15.989652\n",
      "iteration 200 / 2000: loss 11.227759\n",
      "iteration 300 / 2000: loss 8.218278\n",
      "iteration 400 / 2000: loss 6.126812\n",
      "iteration 500 / 2000: loss 4.699799\n",
      "iteration 600 / 2000: loss 3.738636\n",
      "iteration 700 / 2000: loss 3.108535\n",
      "iteration 800 / 2000: loss 2.680608\n",
      "iteration 900 / 2000: loss 2.477329\n",
      "iteration 1000 / 2000: loss 2.117463\n",
      "iteration 1100 / 2000: loss 2.129113\n",
      "iteration 1200 / 2000: loss 2.054970\n",
      "iteration 1300 / 2000: loss 2.049909\n",
      "iteration 1400 / 2000: loss 1.965975\n",
      "iteration 1500 / 2000: loss 1.894750\n",
      "iteration 1600 / 2000: loss 1.813689\n",
      "iteration 1700 / 2000: loss 1.782068\n",
      "iteration 1800 / 2000: loss 1.823809\n",
      "iteration 1900 / 2000: loss 1.834462\n",
      "iteration 0 / 2000: loss 32.853319\n",
      "iteration 100 / 2000: loss 18.648317\n",
      "iteration 200 / 2000: loss 11.726558\n",
      "iteration 300 / 2000: loss 7.708987\n",
      "iteration 400 / 2000: loss 5.392759\n",
      "iteration 500 / 2000: loss 3.894070\n",
      "iteration 600 / 2000: loss 3.116849\n",
      "iteration 700 / 2000: loss 2.591772\n",
      "iteration 800 / 2000: loss 2.202841\n",
      "iteration 900 / 2000: loss 2.163716\n",
      "iteration 1000 / 2000: loss 2.038743\n",
      "iteration 1100 / 2000: loss 2.002743\n",
      "iteration 1200 / 2000: loss 1.899745\n",
      "iteration 1300 / 2000: loss 1.899238\n",
      "iteration 1400 / 2000: loss 1.899749\n",
      "iteration 1500 / 2000: loss 1.835366\n",
      "iteration 1600 / 2000: loss 1.891386\n",
      "iteration 1700 / 2000: loss 1.741744\n",
      "iteration 1800 / 2000: loss 1.905139\n",
      "iteration 1900 / 2000: loss 1.912384\n",
      "iteration 0 / 2000: loss 40.305776\n",
      "iteration 100 / 2000: loss 19.980851\n",
      "iteration 200 / 2000: loss 11.146722\n",
      "iteration 300 / 2000: loss 6.601697\n",
      "iteration 400 / 2000: loss 4.318430\n",
      "iteration 500 / 2000: loss 3.090479\n",
      "iteration 600 / 2000: loss 2.634909\n",
      "iteration 700 / 2000: loss 2.181919\n",
      "iteration 800 / 2000: loss 1.992929\n",
      "iteration 900 / 2000: loss 1.898986\n",
      "iteration 1000 / 2000: loss 1.899698\n",
      "iteration 1100 / 2000: loss 1.919487\n",
      "iteration 1200 / 2000: loss 1.962249\n",
      "iteration 1300 / 2000: loss 1.853978\n",
      "iteration 1400 / 2000: loss 1.900801\n",
      "iteration 1500 / 2000: loss 1.841365\n",
      "iteration 1600 / 2000: loss 1.884374\n",
      "iteration 1700 / 2000: loss 1.836903\n",
      "iteration 1800 / 2000: loss 1.822990\n",
      "iteration 1900 / 2000: loss 1.849104\n",
      "iteration 0 / 2000: loss 46.314878\n",
      "iteration 100 / 2000: loss 20.778495\n",
      "iteration 200 / 2000: loss 10.546732\n",
      "iteration 300 / 2000: loss 5.996962\n",
      "iteration 400 / 2000: loss 3.639146\n",
      "iteration 500 / 2000: loss 2.557017\n",
      "iteration 600 / 2000: loss 2.253959\n",
      "iteration 700 / 2000: loss 1.998705\n",
      "iteration 800 / 2000: loss 1.977510\n",
      "iteration 900 / 2000: loss 2.025273\n",
      "iteration 1000 / 2000: loss 1.753879\n",
      "iteration 1100 / 2000: loss 1.851270\n",
      "iteration 1200 / 2000: loss 1.716887\n",
      "iteration 1300 / 2000: loss 1.915625\n",
      "iteration 1400 / 2000: loss 1.895174\n",
      "iteration 1500 / 2000: loss 1.942147\n",
      "iteration 1600 / 2000: loss 1.861995\n",
      "iteration 1700 / 2000: loss 1.877442\n",
      "iteration 1800 / 2000: loss 1.859889\n",
      "iteration 1900 / 2000: loss 1.789321\n",
      "iteration 0 / 2000: loss 54.140885\n",
      "iteration 100 / 2000: loss 21.616153\n",
      "iteration 200 / 2000: loss 9.911700\n",
      "iteration 300 / 2000: loss 5.138929\n",
      "iteration 400 / 2000: loss 3.187906\n",
      "iteration 500 / 2000: loss 2.379651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 600 / 2000: loss 1.972297\n",
      "iteration 700 / 2000: loss 1.968442\n",
      "iteration 800 / 2000: loss 1.913809\n",
      "iteration 900 / 2000: loss 1.895340\n",
      "iteration 1000 / 2000: loss 1.935696\n",
      "iteration 1100 / 2000: loss 1.983515\n",
      "iteration 1200 / 2000: loss 1.906898\n",
      "iteration 1300 / 2000: loss 1.763096\n",
      "iteration 1400 / 2000: loss 1.814304\n",
      "iteration 1500 / 2000: loss 1.866521\n",
      "iteration 1600 / 2000: loss 1.935497\n",
      "iteration 1700 / 2000: loss 1.943817\n",
      "iteration 1800 / 2000: loss 1.816915\n",
      "iteration 1900 / 2000: loss 1.880693\n",
      "iteration 0 / 2000: loss 61.417662\n",
      "iteration 100 / 2000: loss 21.647634\n",
      "iteration 200 / 2000: loss 8.950317\n",
      "iteration 300 / 2000: loss 4.315030\n",
      "iteration 400 / 2000: loss 2.669174\n",
      "iteration 500 / 2000: loss 2.287147\n",
      "iteration 600 / 2000: loss 1.976735\n",
      "iteration 700 / 2000: loss 1.944433\n",
      "iteration 800 / 2000: loss 2.027243\n",
      "iteration 900 / 2000: loss 1.839329\n",
      "iteration 1000 / 2000: loss 1.890135\n",
      "iteration 1100 / 2000: loss 1.843845\n",
      "iteration 1200 / 2000: loss 1.828247\n",
      "iteration 1300 / 2000: loss 1.852990\n",
      "iteration 1400 / 2000: loss 1.824906\n",
      "iteration 1500 / 2000: loss 1.836808\n",
      "iteration 1600 / 2000: loss 1.900396\n",
      "iteration 1700 / 2000: loss 1.978378\n",
      "iteration 1800 / 2000: loss 1.918723\n",
      "iteration 1900 / 2000: loss 1.872135\n",
      "iteration 0 / 2000: loss 67.592717\n",
      "iteration 100 / 2000: loss 21.340439\n",
      "iteration 200 / 2000: loss 7.874332\n",
      "iteration 300 / 2000: loss 3.799444\n",
      "iteration 400 / 2000: loss 2.459416\n",
      "iteration 500 / 2000: loss 2.030929\n",
      "iteration 600 / 2000: loss 1.971570\n",
      "iteration 700 / 2000: loss 1.928813\n",
      "iteration 800 / 2000: loss 1.840472\n",
      "iteration 900 / 2000: loss 1.796681\n",
      "iteration 1000 / 2000: loss 1.870295\n",
      "iteration 1100 / 2000: loss 1.981563\n",
      "iteration 1200 / 2000: loss 1.794642\n",
      "iteration 1300 / 2000: loss 1.977492\n",
      "iteration 1400 / 2000: loss 1.870561\n",
      "iteration 1500 / 2000: loss 1.821647\n",
      "iteration 1600 / 2000: loss 1.826730\n",
      "iteration 1700 / 2000: loss 1.975162\n",
      "iteration 1800 / 2000: loss 1.909061\n",
      "iteration 1900 / 2000: loss 1.846786\n",
      "iteration 0 / 2000: loss 6.921394\n",
      "iteration 100 / 2000: loss 2.570415\n",
      "iteration 200 / 2000: loss 2.714548\n",
      "iteration 300 / 2000: loss 2.361506\n",
      "iteration 400 / 2000: loss 2.410823\n",
      "iteration 500 / 2000: loss 2.451780\n",
      "iteration 600 / 2000: loss 2.383683\n",
      "iteration 700 / 2000: loss 2.212592\n",
      "iteration 800 / 2000: loss 2.363826\n",
      "iteration 900 / 2000: loss 2.243883\n",
      "iteration 1000 / 2000: loss 2.235269\n",
      "iteration 1100 / 2000: loss 2.216279\n",
      "iteration 1200 / 2000: loss 2.274434\n",
      "iteration 1300 / 2000: loss 2.111237\n",
      "iteration 1400 / 2000: loss 2.085190\n",
      "iteration 1500 / 2000: loss 1.963375\n",
      "iteration 1600 / 2000: loss 2.170820\n",
      "iteration 1700 / 2000: loss 2.186362\n",
      "iteration 1800 / 2000: loss 2.156933\n",
      "iteration 1900 / 2000: loss 2.295571\n",
      "iteration 0 / 2000: loss 12.092773\n",
      "iteration 100 / 2000: loss 8.501979\n",
      "iteration 200 / 2000: loss 7.335009\n",
      "iteration 300 / 2000: loss 6.273941\n",
      "iteration 400 / 2000: loss 5.650061\n",
      "iteration 500 / 2000: loss 5.004378\n",
      "iteration 600 / 2000: loss 4.528235\n",
      "iteration 700 / 2000: loss 4.242379\n",
      "iteration 800 / 2000: loss 3.851800\n",
      "iteration 900 / 2000: loss 3.418393\n",
      "iteration 1000 / 2000: loss 3.305851\n",
      "iteration 1100 / 2000: loss 2.967654\n",
      "iteration 1200 / 2000: loss 2.834954\n",
      "iteration 1300 / 2000: loss 2.701578\n",
      "iteration 1400 / 2000: loss 2.600468\n",
      "iteration 1500 / 2000: loss 2.396447\n",
      "iteration 1600 / 2000: loss 2.202236\n",
      "iteration 1700 / 2000: loss 2.307622\n",
      "iteration 1800 / 2000: loss 2.258447\n",
      "iteration 1900 / 2000: loss 2.098918\n",
      "iteration 0 / 2000: loss 18.783578\n",
      "iteration 100 / 2000: loss 12.447216\n",
      "iteration 200 / 2000: loss 9.563981\n",
      "iteration 300 / 2000: loss 7.466254\n",
      "iteration 400 / 2000: loss 6.058099\n",
      "iteration 500 / 2000: loss 4.905048\n",
      "iteration 600 / 2000: loss 4.131521\n",
      "iteration 700 / 2000: loss 3.452780\n",
      "iteration 800 / 2000: loss 2.996475\n",
      "iteration 900 / 2000: loss 2.734565\n",
      "iteration 1000 / 2000: loss 2.538917\n",
      "iteration 1100 / 2000: loss 2.435621\n",
      "iteration 1200 / 2000: loss 2.108095\n",
      "iteration 1300 / 2000: loss 1.986918\n",
      "iteration 1400 / 2000: loss 1.999853\n",
      "iteration 1500 / 2000: loss 2.008629\n",
      "iteration 1600 / 2000: loss 1.979028\n",
      "iteration 1700 / 2000: loss 1.905701\n",
      "iteration 1800 / 2000: loss 2.029552\n",
      "iteration 1900 / 2000: loss 1.853322\n",
      "iteration 0 / 2000: loss 26.060082\n",
      "iteration 100 / 2000: loss 15.403569\n",
      "iteration 200 / 2000: loss 10.363640\n",
      "iteration 300 / 2000: loss 7.300266\n",
      "iteration 400 / 2000: loss 5.384859\n",
      "iteration 500 / 2000: loss 4.014548\n",
      "iteration 600 / 2000: loss 3.168290\n",
      "iteration 700 / 2000: loss 2.740891\n",
      "iteration 800 / 2000: loss 2.369740\n",
      "iteration 900 / 2000: loss 2.218654\n",
      "iteration 1000 / 2000: loss 1.909671\n",
      "iteration 1100 / 2000: loss 1.927222\n",
      "iteration 1200 / 2000: loss 1.952869\n",
      "iteration 1300 / 2000: loss 1.842386\n",
      "iteration 1400 / 2000: loss 1.900498\n",
      "iteration 1500 / 2000: loss 1.792596\n",
      "iteration 1600 / 2000: loss 1.793911\n",
      "iteration 1700 / 2000: loss 1.829649\n",
      "iteration 1800 / 2000: loss 1.908668\n",
      "iteration 1900 / 2000: loss 1.815583\n",
      "iteration 0 / 2000: loss 32.606294\n",
      "iteration 100 / 2000: loss 17.104447\n",
      "iteration 200 / 2000: loss 10.205805\n",
      "iteration 300 / 2000: loss 6.359585\n",
      "iteration 400 / 2000: loss 4.482165\n",
      "iteration 500 / 2000: loss 3.228320\n",
      "iteration 600 / 2000: loss 2.575884\n",
      "iteration 700 / 2000: loss 2.313551\n",
      "iteration 800 / 2000: loss 2.082027\n",
      "iteration 900 / 2000: loss 1.952214\n",
      "iteration 1000 / 2000: loss 1.956917\n",
      "iteration 1100 / 2000: loss 1.864550\n",
      "iteration 1200 / 2000: loss 1.736107\n",
      "iteration 1300 / 2000: loss 1.862799\n",
      "iteration 1400 / 2000: loss 1.821999\n",
      "iteration 1500 / 2000: loss 1.791934\n",
      "iteration 1600 / 2000: loss 1.793784\n",
      "iteration 1700 / 2000: loss 1.706445\n",
      "iteration 1800 / 2000: loss 1.956635\n",
      "iteration 1900 / 2000: loss 1.862154\n",
      "iteration 0 / 2000: loss 40.474439\n",
      "iteration 100 / 2000: loss 18.696985\n",
      "iteration 200 / 2000: loss 9.854886\n",
      "iteration 300 / 2000: loss 5.718828\n",
      "iteration 400 / 2000: loss 3.682877\n",
      "iteration 500 / 2000: loss 2.712887\n",
      "iteration 600 / 2000: loss 2.309781\n",
      "iteration 700 / 2000: loss 2.025194\n",
      "iteration 800 / 2000: loss 2.009790\n",
      "iteration 900 / 2000: loss 1.870620\n",
      "iteration 1000 / 2000: loss 1.770613\n",
      "iteration 1100 / 2000: loss 1.919798\n",
      "iteration 1200 / 2000: loss 1.852324\n",
      "iteration 1300 / 2000: loss 1.779651\n",
      "iteration 1400 / 2000: loss 1.815475\n",
      "iteration 1500 / 2000: loss 1.896508\n",
      "iteration 1600 / 2000: loss 1.859693\n",
      "iteration 1700 / 2000: loss 1.859905\n",
      "iteration 1800 / 2000: loss 1.916922\n",
      "iteration 1900 / 2000: loss 1.732141\n",
      "iteration 0 / 2000: loss 46.352158\n",
      "iteration 100 / 2000: loss 19.198764\n",
      "iteration 200 / 2000: loss 8.970200\n",
      "iteration 300 / 2000: loss 4.884315\n",
      "iteration 400 / 2000: loss 3.091066\n",
      "iteration 500 / 2000: loss 2.378575\n",
      "iteration 600 / 2000: loss 2.119434\n",
      "iteration 700 / 2000: loss 1.962180\n",
      "iteration 800 / 2000: loss 1.861724\n",
      "iteration 900 / 2000: loss 1.869122\n",
      "iteration 1000 / 2000: loss 1.881201\n",
      "iteration 1100 / 2000: loss 1.902721\n",
      "iteration 1200 / 2000: loss 1.961189\n",
      "iteration 1300 / 2000: loss 1.713731\n",
      "iteration 1400 / 2000: loss 1.896677\n",
      "iteration 1500 / 2000: loss 1.903334\n",
      "iteration 1600 / 2000: loss 1.825828\n",
      "iteration 1700 / 2000: loss 1.960044\n",
      "iteration 1800 / 2000: loss 1.934501\n",
      "iteration 1900 / 2000: loss 1.722960\n",
      "iteration 0 / 2000: loss 52.514285\n",
      "iteration 100 / 2000: loss 19.246474\n",
      "iteration 200 / 2000: loss 7.949733\n",
      "iteration 300 / 2000: loss 4.069695\n",
      "iteration 400 / 2000: loss 2.673824\n",
      "iteration 500 / 2000: loss 2.097665\n",
      "iteration 600 / 2000: loss 1.917506\n",
      "iteration 700 / 2000: loss 1.896119\n",
      "iteration 800 / 2000: loss 1.925232\n",
      "iteration 900 / 2000: loss 1.788136\n",
      "iteration 1000 / 2000: loss 1.775475\n",
      "iteration 1100 / 2000: loss 1.806236\n",
      "iteration 1200 / 2000: loss 1.852516\n",
      "iteration 1300 / 2000: loss 1.841525\n",
      "iteration 1400 / 2000: loss 1.967727\n",
      "iteration 1500 / 2000: loss 1.844168\n",
      "iteration 1600 / 2000: loss 1.892406\n",
      "iteration 1700 / 2000: loss 1.846403\n",
      "iteration 1800 / 2000: loss 1.952520\n",
      "iteration 1900 / 2000: loss 1.842705\n",
      "iteration 0 / 2000: loss 62.084470\n",
      "iteration 100 / 2000: loss 19.105397\n",
      "iteration 200 / 2000: loss 7.190169\n",
      "iteration 300 / 2000: loss 3.567548\n",
      "iteration 400 / 2000: loss 2.472149\n",
      "iteration 500 / 2000: loss 1.986436\n",
      "iteration 600 / 2000: loss 1.922434\n",
      "iteration 700 / 2000: loss 1.942363\n",
      "iteration 800 / 2000: loss 1.958951\n",
      "iteration 900 / 2000: loss 1.855184\n",
      "iteration 1000 / 2000: loss 1.852251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1100 / 2000: loss 1.822817\n",
      "iteration 1200 / 2000: loss 1.868209\n",
      "iteration 1300 / 2000: loss 1.931671\n",
      "iteration 1400 / 2000: loss 1.795599\n",
      "iteration 1500 / 2000: loss 1.920795\n",
      "iteration 1600 / 2000: loss 1.879019\n",
      "iteration 1700 / 2000: loss 1.880090\n",
      "iteration 1800 / 2000: loss 1.879557\n",
      "iteration 1900 / 2000: loss 1.951326\n",
      "iteration 0 / 2000: loss 68.371853\n",
      "iteration 100 / 2000: loss 18.622202\n",
      "iteration 200 / 2000: loss 6.463794\n",
      "iteration 300 / 2000: loss 3.019698\n",
      "iteration 400 / 2000: loss 2.063318\n",
      "iteration 500 / 2000: loss 1.851862\n",
      "iteration 600 / 2000: loss 1.954611\n",
      "iteration 700 / 2000: loss 1.816030\n",
      "iteration 800 / 2000: loss 1.838760\n",
      "iteration 900 / 2000: loss 1.846757\n",
      "iteration 1000 / 2000: loss 1.903307\n",
      "iteration 1100 / 2000: loss 1.905738\n",
      "iteration 1200 / 2000: loss 1.892623\n",
      "iteration 1300 / 2000: loss 1.885176\n",
      "iteration 1400 / 2000: loss 1.904240\n",
      "iteration 1500 / 2000: loss 1.906174\n",
      "iteration 1600 / 2000: loss 1.787650\n",
      "iteration 1700 / 2000: loss 1.842832\n",
      "iteration 1800 / 2000: loss 1.930817\n",
      "iteration 1900 / 2000: loss 1.866317\n",
      "iteration 0 / 2000: loss 5.851300\n",
      "iteration 100 / 2000: loss 2.901051\n",
      "iteration 200 / 2000: loss 2.631622\n",
      "iteration 300 / 2000: loss 2.578252\n",
      "iteration 400 / 2000: loss 2.413295\n",
      "iteration 500 / 2000: loss 2.310647\n",
      "iteration 600 / 2000: loss 2.191435\n",
      "iteration 700 / 2000: loss 2.084595\n",
      "iteration 800 / 2000: loss 2.289513\n",
      "iteration 900 / 2000: loss 2.228644\n",
      "iteration 1000 / 2000: loss 2.051064\n",
      "iteration 1100 / 2000: loss 2.081262\n",
      "iteration 1200 / 2000: loss 2.248339\n",
      "iteration 1300 / 2000: loss 2.092788\n",
      "iteration 1400 / 2000: loss 2.026077\n",
      "iteration 1500 / 2000: loss 2.004706\n",
      "iteration 1600 / 2000: loss 2.104776\n",
      "iteration 1700 / 2000: loss 2.074136\n",
      "iteration 1800 / 2000: loss 2.110524\n",
      "iteration 1900 / 2000: loss 1.891685\n",
      "iteration 0 / 2000: loss 12.780390\n",
      "iteration 100 / 2000: loss 8.321813\n",
      "iteration 200 / 2000: loss 7.012756\n",
      "iteration 300 / 2000: loss 6.053729\n",
      "iteration 400 / 2000: loss 5.374388\n",
      "iteration 500 / 2000: loss 4.789380\n",
      "iteration 600 / 2000: loss 4.369925\n",
      "iteration 700 / 2000: loss 3.934598\n",
      "iteration 800 / 2000: loss 3.641557\n",
      "iteration 900 / 2000: loss 3.301631\n",
      "iteration 1000 / 2000: loss 3.005823\n",
      "iteration 1100 / 2000: loss 2.929428\n",
      "iteration 1200 / 2000: loss 2.661256\n",
      "iteration 1300 / 2000: loss 2.449051\n",
      "iteration 1400 / 2000: loss 2.362401\n",
      "iteration 1500 / 2000: loss 2.338557\n",
      "iteration 1600 / 2000: loss 2.130346\n",
      "iteration 1700 / 2000: loss 2.188045\n",
      "iteration 1800 / 2000: loss 2.076954\n",
      "iteration 1900 / 2000: loss 2.029506\n",
      "iteration 0 / 2000: loss 19.592559\n",
      "iteration 100 / 2000: loss 12.385949\n",
      "iteration 200 / 2000: loss 9.161443\n",
      "iteration 300 / 2000: loss 7.025298\n",
      "iteration 400 / 2000: loss 5.557080\n",
      "iteration 500 / 2000: loss 4.425868\n",
      "iteration 600 / 2000: loss 3.715739\n",
      "iteration 700 / 2000: loss 3.107995\n",
      "iteration 800 / 2000: loss 2.786090\n",
      "iteration 900 / 2000: loss 2.481154\n",
      "iteration 1000 / 2000: loss 2.408885\n",
      "iteration 1100 / 2000: loss 2.186950\n",
      "iteration 1200 / 2000: loss 1.992988\n",
      "iteration 1300 / 2000: loss 1.927857\n",
      "iteration 1400 / 2000: loss 2.025839\n",
      "iteration 1500 / 2000: loss 1.845946\n",
      "iteration 1600 / 2000: loss 1.857465\n",
      "iteration 1700 / 2000: loss 1.851361\n",
      "iteration 1800 / 2000: loss 1.869384\n",
      "iteration 1900 / 2000: loss 1.852304\n",
      "iteration 0 / 2000: loss 26.279402\n",
      "iteration 100 / 2000: loss 14.711426\n",
      "iteration 200 / 2000: loss 9.387705\n",
      "iteration 300 / 2000: loss 6.453140\n",
      "iteration 400 / 2000: loss 4.518599\n",
      "iteration 500 / 2000: loss 3.646876\n",
      "iteration 600 / 2000: loss 2.894759\n",
      "iteration 700 / 2000: loss 2.511859\n",
      "iteration 800 / 2000: loss 2.152000\n",
      "iteration 900 / 2000: loss 2.010904\n",
      "iteration 1000 / 2000: loss 1.955870\n",
      "iteration 1100 / 2000: loss 1.893137\n",
      "iteration 1200 / 2000: loss 1.972531\n",
      "iteration 1300 / 2000: loss 1.899695\n",
      "iteration 1400 / 2000: loss 1.885629\n",
      "iteration 1500 / 2000: loss 1.857510\n",
      "iteration 1600 / 2000: loss 1.885505\n",
      "iteration 1700 / 2000: loss 1.883127\n",
      "iteration 1800 / 2000: loss 1.728158\n",
      "iteration 1900 / 2000: loss 1.826882\n",
      "iteration 0 / 2000: loss 33.828753\n",
      "iteration 100 / 2000: loss 16.276573\n",
      "iteration 200 / 2000: loss 9.223786\n",
      "iteration 300 / 2000: loss 5.557090\n",
      "iteration 400 / 2000: loss 3.778780\n",
      "iteration 500 / 2000: loss 2.867152\n",
      "iteration 600 / 2000: loss 2.384761\n",
      "iteration 700 / 2000: loss 2.099734\n",
      "iteration 800 / 2000: loss 1.973190\n",
      "iteration 900 / 2000: loss 1.819196\n",
      "iteration 1000 / 2000: loss 1.963750\n",
      "iteration 1100 / 2000: loss 1.864144\n",
      "iteration 1200 / 2000: loss 1.858835\n",
      "iteration 1300 / 2000: loss 1.842051\n",
      "iteration 1400 / 2000: loss 1.809942\n",
      "iteration 1500 / 2000: loss 1.876284\n",
      "iteration 1600 / 2000: loss 1.887800\n",
      "iteration 1700 / 2000: loss 1.825034\n",
      "iteration 1800 / 2000: loss 1.766529\n",
      "iteration 1900 / 2000: loss 1.847148\n",
      "iteration 0 / 2000: loss 39.647870\n",
      "iteration 100 / 2000: loss 17.239282\n",
      "iteration 200 / 2000: loss 8.566183\n",
      "iteration 300 / 2000: loss 4.806384\n",
      "iteration 400 / 2000: loss 3.049130\n",
      "iteration 500 / 2000: loss 2.508045\n",
      "iteration 600 / 2000: loss 2.005305\n",
      "iteration 700 / 2000: loss 1.895863\n",
      "iteration 800 / 2000: loss 1.919554\n",
      "iteration 900 / 2000: loss 1.811240\n",
      "iteration 1000 / 2000: loss 1.890938\n",
      "iteration 1100 / 2000: loss 1.994903\n",
      "iteration 1200 / 2000: loss 1.828688\n",
      "iteration 1300 / 2000: loss 1.918866\n",
      "iteration 1400 / 2000: loss 1.931571\n",
      "iteration 1500 / 2000: loss 1.761146\n",
      "iteration 1600 / 2000: loss 1.919435\n",
      "iteration 1700 / 2000: loss 1.866361\n",
      "iteration 1800 / 2000: loss 1.874355\n",
      "iteration 1900 / 2000: loss 1.776180\n",
      "iteration 0 / 2000: loss 47.568953\n",
      "iteration 100 / 2000: loss 17.579934\n",
      "iteration 200 / 2000: loss 7.670388\n",
      "iteration 300 / 2000: loss 4.011991\n",
      "iteration 400 / 2000: loss 2.598559\n",
      "iteration 500 / 2000: loss 2.209360\n",
      "iteration 600 / 2000: loss 1.962938\n",
      "iteration 700 / 2000: loss 1.839735\n",
      "iteration 800 / 2000: loss 2.005192\n",
      "iteration 900 / 2000: loss 1.855634\n",
      "iteration 1000 / 2000: loss 1.898908\n",
      "iteration 1100 / 2000: loss 1.931638\n",
      "iteration 1200 / 2000: loss 1.944896\n",
      "iteration 1300 / 2000: loss 1.864930\n",
      "iteration 1400 / 2000: loss 1.834712\n",
      "iteration 1500 / 2000: loss 1.967491\n",
      "iteration 1600 / 2000: loss 1.945101\n",
      "iteration 1700 / 2000: loss 1.832412\n",
      "iteration 1800 / 2000: loss 1.690150\n",
      "iteration 1900 / 2000: loss 1.817036\n",
      "iteration 0 / 2000: loss 52.568778\n",
      "iteration 100 / 2000: loss 16.994160\n",
      "iteration 200 / 2000: loss 6.749528\n",
      "iteration 300 / 2000: loss 3.445938\n",
      "iteration 400 / 2000: loss 2.432306\n",
      "iteration 500 / 2000: loss 1.927652\n",
      "iteration 600 / 2000: loss 1.975968\n",
      "iteration 700 / 2000: loss 1.848875\n",
      "iteration 800 / 2000: loss 1.899474\n",
      "iteration 900 / 2000: loss 1.883290\n",
      "iteration 1000 / 2000: loss 1.789456\n",
      "iteration 1100 / 2000: loss 1.929706\n",
      "iteration 1200 / 2000: loss 1.861047\n",
      "iteration 1300 / 2000: loss 1.891968\n",
      "iteration 1400 / 2000: loss 1.893419\n",
      "iteration 1500 / 2000: loss 1.981414\n",
      "iteration 1600 / 2000: loss 1.846590\n",
      "iteration 1700 / 2000: loss 1.883984\n",
      "iteration 1800 / 2000: loss 1.870303\n",
      "iteration 1900 / 2000: loss 1.899050\n",
      "iteration 0 / 2000: loss 60.496672\n",
      "iteration 100 / 2000: loss 16.935740\n",
      "iteration 200 / 2000: loss 5.852624\n",
      "iteration 300 / 2000: loss 3.071367\n",
      "iteration 400 / 2000: loss 2.293639\n",
      "iteration 500 / 2000: loss 1.890310\n",
      "iteration 600 / 2000: loss 1.923774\n",
      "iteration 700 / 2000: loss 1.796739\n",
      "iteration 800 / 2000: loss 1.896647\n",
      "iteration 900 / 2000: loss 1.876296\n",
      "iteration 1000 / 2000: loss 1.923006\n",
      "iteration 1100 / 2000: loss 1.860134\n",
      "iteration 1200 / 2000: loss 1.910233\n",
      "iteration 1300 / 2000: loss 1.811750\n",
      "iteration 1400 / 2000: loss 1.966084\n",
      "iteration 1500 / 2000: loss 1.877862\n",
      "iteration 1600 / 2000: loss 1.958188\n",
      "iteration 1700 / 2000: loss 1.914853\n",
      "iteration 1800 / 2000: loss 1.849087\n",
      "iteration 1900 / 2000: loss 1.824975\n",
      "iteration 0 / 2000: loss 66.552404\n",
      "iteration 100 / 2000: loss 15.941925\n",
      "iteration 200 / 2000: loss 5.063810\n",
      "iteration 300 / 2000: loss 2.656117\n",
      "iteration 400 / 2000: loss 2.165240\n",
      "iteration 500 / 2000: loss 1.871068\n",
      "iteration 600 / 2000: loss 1.977189\n",
      "iteration 700 / 2000: loss 1.925766\n",
      "iteration 800 / 2000: loss 1.872162\n",
      "iteration 900 / 2000: loss 1.983508\n",
      "iteration 1000 / 2000: loss 1.911525\n",
      "iteration 1100 / 2000: loss 1.882782\n",
      "iteration 1200 / 2000: loss 1.922883\n",
      "iteration 1300 / 2000: loss 1.876933\n",
      "iteration 1400 / 2000: loss 1.990114\n",
      "iteration 1500 / 2000: loss 1.930678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1600 / 2000: loss 1.867479\n",
      "iteration 1700 / 2000: loss 1.919966\n",
      "iteration 1800 / 2000: loss 2.000973\n",
      "iteration 1900 / 2000: loss 1.818561\n",
      "iteration 0 / 2000: loss 5.038085\n",
      "iteration 100 / 2000: loss 2.993895\n",
      "iteration 200 / 2000: loss 2.704884\n",
      "iteration 300 / 2000: loss 2.465521\n",
      "iteration 400 / 2000: loss 2.642118\n",
      "iteration 500 / 2000: loss 2.319670\n",
      "iteration 600 / 2000: loss 2.519688\n",
      "iteration 700 / 2000: loss 2.173919\n",
      "iteration 800 / 2000: loss 2.169339\n",
      "iteration 900 / 2000: loss 2.336566\n",
      "iteration 1000 / 2000: loss 2.065500\n",
      "iteration 1100 / 2000: loss 2.050111\n",
      "iteration 1200 / 2000: loss 2.089909\n",
      "iteration 1300 / 2000: loss 2.046242\n",
      "iteration 1400 / 2000: loss 2.157320\n",
      "iteration 1500 / 2000: loss 2.089032\n",
      "iteration 1600 / 2000: loss 2.027657\n",
      "iteration 1700 / 2000: loss 1.906884\n",
      "iteration 1800 / 2000: loss 2.027891\n",
      "iteration 1900 / 2000: loss 2.031821\n",
      "iteration 0 / 2000: loss 12.943819\n",
      "iteration 100 / 2000: loss 8.357704\n",
      "iteration 200 / 2000: loss 6.838746\n",
      "iteration 300 / 2000: loss 5.955462\n",
      "iteration 400 / 2000: loss 5.183134\n",
      "iteration 500 / 2000: loss 4.535239\n",
      "iteration 600 / 2000: loss 4.098276\n",
      "iteration 700 / 2000: loss 3.534037\n",
      "iteration 800 / 2000: loss 3.326150\n",
      "iteration 900 / 2000: loss 3.003630\n",
      "iteration 1000 / 2000: loss 2.925229\n",
      "iteration 1100 / 2000: loss 2.591584\n",
      "iteration 1200 / 2000: loss 2.492404\n",
      "iteration 1300 / 2000: loss 2.287681\n",
      "iteration 1400 / 2000: loss 2.254278\n",
      "iteration 1500 / 2000: loss 2.166813\n",
      "iteration 1600 / 2000: loss 2.078427\n",
      "iteration 1700 / 2000: loss 2.082132\n",
      "iteration 1800 / 2000: loss 1.947563\n",
      "iteration 1900 / 2000: loss 1.848116\n",
      "iteration 0 / 2000: loss 18.466702\n",
      "iteration 100 / 2000: loss 11.989790\n",
      "iteration 200 / 2000: loss 8.496388\n",
      "iteration 300 / 2000: loss 6.478401\n",
      "iteration 400 / 2000: loss 4.875964\n",
      "iteration 500 / 2000: loss 3.962522\n",
      "iteration 600 / 2000: loss 3.303049\n",
      "iteration 700 / 2000: loss 2.819111\n",
      "iteration 800 / 2000: loss 2.394433\n",
      "iteration 900 / 2000: loss 2.244002\n",
      "iteration 1000 / 2000: loss 2.144516\n",
      "iteration 1100 / 2000: loss 1.956744\n",
      "iteration 1200 / 2000: loss 1.941928\n",
      "iteration 1300 / 2000: loss 1.935916\n",
      "iteration 1400 / 2000: loss 1.890855\n",
      "iteration 1500 / 2000: loss 1.886986\n",
      "iteration 1600 / 2000: loss 1.821624\n",
      "iteration 1700 / 2000: loss 1.834706\n",
      "iteration 1800 / 2000: loss 1.870636\n",
      "iteration 1900 / 2000: loss 1.852324\n",
      "iteration 0 / 2000: loss 26.772581\n",
      "iteration 100 / 2000: loss 14.450097\n",
      "iteration 200 / 2000: loss 8.860752\n",
      "iteration 300 / 2000: loss 5.831598\n",
      "iteration 400 / 2000: loss 4.151330\n",
      "iteration 500 / 2000: loss 3.092230\n",
      "iteration 600 / 2000: loss 2.563481\n",
      "iteration 700 / 2000: loss 2.313234\n",
      "iteration 800 / 2000: loss 2.012597\n",
      "iteration 900 / 2000: loss 1.954055\n",
      "iteration 1000 / 2000: loss 2.044664\n",
      "iteration 1100 / 2000: loss 1.816603\n",
      "iteration 1200 / 2000: loss 1.798794\n",
      "iteration 1300 / 2000: loss 1.792236\n",
      "iteration 1400 / 2000: loss 1.864400\n",
      "iteration 1500 / 2000: loss 1.893128\n",
      "iteration 1600 / 2000: loss 1.712906\n",
      "iteration 1700 / 2000: loss 1.909300\n",
      "iteration 1800 / 2000: loss 1.906554\n",
      "iteration 1900 / 2000: loss 1.962635\n",
      "iteration 0 / 2000: loss 33.585908\n",
      "iteration 100 / 2000: loss 15.228240\n",
      "iteration 200 / 2000: loss 8.239691\n",
      "iteration 300 / 2000: loss 4.923505\n",
      "iteration 400 / 2000: loss 3.318968\n",
      "iteration 500 / 2000: loss 2.572213\n",
      "iteration 600 / 2000: loss 2.047167\n",
      "iteration 700 / 2000: loss 2.001252\n",
      "iteration 800 / 2000: loss 1.883190\n",
      "iteration 900 / 2000: loss 1.843713\n",
      "iteration 1000 / 2000: loss 1.889756\n",
      "iteration 1100 / 2000: loss 1.903557\n",
      "iteration 1200 / 2000: loss 1.759586\n",
      "iteration 1300 / 2000: loss 1.870034\n",
      "iteration 1400 / 2000: loss 1.864641\n",
      "iteration 1500 / 2000: loss 1.881276\n",
      "iteration 1600 / 2000: loss 1.880809\n",
      "iteration 1700 / 2000: loss 1.914209\n",
      "iteration 1800 / 2000: loss 1.803361\n",
      "iteration 1900 / 2000: loss 1.887111\n",
      "iteration 0 / 2000: loss 39.867925\n",
      "iteration 100 / 2000: loss 15.788282\n",
      "iteration 200 / 2000: loss 7.453214\n",
      "iteration 300 / 2000: loss 4.060406\n",
      "iteration 400 / 2000: loss 2.835599\n",
      "iteration 500 / 2000: loss 2.369341\n",
      "iteration 600 / 2000: loss 1.997495\n",
      "iteration 700 / 2000: loss 1.923187\n",
      "iteration 800 / 2000: loss 1.818430\n",
      "iteration 900 / 2000: loss 1.885269\n",
      "iteration 1000 / 2000: loss 1.993108\n",
      "iteration 1100 / 2000: loss 1.835452\n",
      "iteration 1200 / 2000: loss 1.819779\n",
      "iteration 1300 / 2000: loss 1.768921\n",
      "iteration 1400 / 2000: loss 1.841106\n",
      "iteration 1500 / 2000: loss 1.983926\n",
      "iteration 1600 / 2000: loss 1.872767\n",
      "iteration 1700 / 2000: loss 1.808232\n",
      "iteration 1800 / 2000: loss 1.956662\n",
      "iteration 1900 / 2000: loss 1.869815\n",
      "iteration 0 / 2000: loss 47.189744\n",
      "iteration 100 / 2000: loss 15.976792\n",
      "iteration 200 / 2000: loss 6.651184\n",
      "iteration 300 / 2000: loss 3.421580\n",
      "iteration 400 / 2000: loss 2.378398\n",
      "iteration 500 / 2000: loss 2.048203\n",
      "iteration 600 / 2000: loss 1.932840\n",
      "iteration 700 / 2000: loss 1.863271\n",
      "iteration 800 / 2000: loss 1.967013\n",
      "iteration 900 / 2000: loss 1.808285\n",
      "iteration 1000 / 2000: loss 1.977161\n",
      "iteration 1100 / 2000: loss 1.922635\n",
      "iteration 1200 / 2000: loss 1.834667\n",
      "iteration 1300 / 2000: loss 1.890362\n",
      "iteration 1400 / 2000: loss 1.895271\n",
      "iteration 1500 / 2000: loss 1.809695\n",
      "iteration 1600 / 2000: loss 1.787863\n",
      "iteration 1700 / 2000: loss 1.971193\n",
      "iteration 1800 / 2000: loss 1.884444\n",
      "iteration 1900 / 2000: loss 1.781162\n",
      "iteration 0 / 2000: loss 53.146424\n",
      "iteration 100 / 2000: loss 15.491789\n",
      "iteration 200 / 2000: loss 5.727068\n",
      "iteration 300 / 2000: loss 2.919116\n",
      "iteration 400 / 2000: loss 2.186189\n",
      "iteration 500 / 2000: loss 1.906988\n",
      "iteration 600 / 2000: loss 1.845591\n",
      "iteration 700 / 2000: loss 1.882651\n",
      "iteration 800 / 2000: loss 1.807431\n",
      "iteration 900 / 2000: loss 1.856844\n",
      "iteration 1000 / 2000: loss 1.884513\n",
      "iteration 1100 / 2000: loss 1.872947\n",
      "iteration 1200 / 2000: loss 1.911203\n",
      "iteration 1300 / 2000: loss 1.790473\n",
      "iteration 1400 / 2000: loss 1.953523\n",
      "iteration 1500 / 2000: loss 1.837844\n",
      "iteration 1600 / 2000: loss 1.927953\n",
      "iteration 1700 / 2000: loss 1.835017\n",
      "iteration 1800 / 2000: loss 1.890488\n",
      "iteration 1900 / 2000: loss 1.948061\n",
      "iteration 0 / 2000: loss 61.748632\n",
      "iteration 100 / 2000: loss 14.970774\n",
      "iteration 200 / 2000: loss 4.862986\n",
      "iteration 300 / 2000: loss 2.536186\n",
      "iteration 400 / 2000: loss 2.042151\n",
      "iteration 500 / 2000: loss 1.875321\n",
      "iteration 600 / 2000: loss 1.838889\n",
      "iteration 700 / 2000: loss 1.948422\n",
      "iteration 800 / 2000: loss 1.910285\n",
      "iteration 900 / 2000: loss 1.942096\n",
      "iteration 1000 / 2000: loss 1.824539\n",
      "iteration 1100 / 2000: loss 1.803553\n",
      "iteration 1200 / 2000: loss 1.944429\n",
      "iteration 1300 / 2000: loss 1.865997\n",
      "iteration 1400 / 2000: loss 1.858827\n",
      "iteration 1500 / 2000: loss 1.866331\n",
      "iteration 1600 / 2000: loss 1.820068\n",
      "iteration 1700 / 2000: loss 1.891201\n",
      "iteration 1800 / 2000: loss 1.844932\n",
      "iteration 1900 / 2000: loss 1.976790\n",
      "iteration 0 / 2000: loss 66.989415\n",
      "iteration 100 / 2000: loss 13.913553\n",
      "iteration 200 / 2000: loss 4.344681\n",
      "iteration 300 / 2000: loss 2.380963\n",
      "iteration 400 / 2000: loss 2.098062\n",
      "iteration 500 / 2000: loss 1.895613\n",
      "iteration 600 / 2000: loss 1.864490\n",
      "iteration 700 / 2000: loss 1.836242\n",
      "iteration 800 / 2000: loss 1.970065\n",
      "iteration 900 / 2000: loss 1.890381\n",
      "iteration 1000 / 2000: loss 1.842007\n",
      "iteration 1100 / 2000: loss 1.800482\n",
      "iteration 1200 / 2000: loss 1.970533\n",
      "iteration 1300 / 2000: loss 1.846401\n",
      "iteration 1400 / 2000: loss 1.830034\n",
      "iteration 1500 / 2000: loss 1.865579\n",
      "iteration 1600 / 2000: loss 1.921739\n",
      "iteration 1700 / 2000: loss 1.859327\n",
      "iteration 1800 / 2000: loss 1.955914\n",
      "iteration 1900 / 2000: loss 1.883407\n",
      "lr 3.000000e-07 reg 2.000000e+03 train accuracy: 0.390224 val accuracy: 0.396000\n",
      "lr 4.888889e-07 reg 2.000000e+03 train accuracy: 0.390898 val accuracy: 0.393000\n",
      "lr 6.777778e-07 reg 2.000000e+03 train accuracy: 0.389592 val accuracy: 0.405000\n",
      "lr 8.666667e-07 reg 2.000000e+03 train accuracy: 0.390592 val accuracy: 0.386000\n",
      "lr 1.055556e-06 reg 2.000000e+03 train accuracy: 0.390673 val accuracy: 0.413000\n",
      "lr 1.244444e-06 reg 2.000000e+03 train accuracy: 0.386429 val accuracy: 0.394000\n",
      "lr 1.433333e-06 reg 2.000000e+03 train accuracy: 0.383204 val accuracy: 0.391000\n",
      "lr 1.622222e-06 reg 2.000000e+03 train accuracy: 0.382000 val accuracy: 0.394000\n",
      "lr 1.811111e-06 reg 2.000000e+03 train accuracy: 0.382735 val accuracy: 0.382000\n",
      "lr 2.000000e-06 reg 2.000000e+03 train accuracy: 0.382571 val accuracy: 0.389000\n",
      "best validation accuracy achieved during cross-validation: 0.415000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "##################################\n",
    "# rk's remark:                   #\n",
    "#          random search         #\n",
    "##################################\n",
    "\n",
    "# sample learning_rates\n",
    "exp_lr = -10 * np.random.rand(10)\n",
    "learning_rates = np.power(10, exp_lr)\n",
    "\n",
    "# sample regs\n",
    "exp_reg = 7 * np.random.rand(10)\n",
    "reg_strengths = np.power(10, exp_reg)\n",
    "para_group = [(np.random.choice(learning_rates, replace=False), \n",
    "               np.random.choice(reg_strengths, replace=False)) for _ in range(20)]\n",
    "\n",
    "###  comment out after try out coarse grid\n",
    "# for lr, reg in para_group:\n",
    "#     softmax = Softmax()\n",
    "#     loss_history = softmax.train(X_train, y_train, learning_rate=lr, reg=reg,\n",
    "#                                  num_iters=2000, verbose=True)\n",
    "#     y_train_pred = softmax.predict(X_train)\n",
    "#     train_acc = np.sum((y_train_pred == y_train)) / y_train.shape[0]\n",
    "#     y_val_pred = softmax.predict(X_val)\n",
    "#     val_acc = np.sum((y_val_pred == y_val)) / y_val.shape[0]\n",
    "#     if(val_acc > best_val):\n",
    "#         best_val=val_acc\n",
    "#         best_softmax=softmax\n",
    "#     results[(lr,reg)]=(train_acc,val_acc)\n",
    "###  best result from coarse grid: \n",
    "###  => best validation accuracy achieved during cross-validation: 0.416000\n",
    "\n",
    "### refine grid\n",
    "lr_fine = [3e-7, 2e-6]\n",
    "reg_fine = [1e1, 2e3]\n",
    "\n",
    "for lr in np.linspace(lr_fine[0], lr_fine[1], 10):\n",
    "    for reg in np.linspace(reg_fine[0], reg_fine[1], 10):\n",
    "        softmax = Softmax()\n",
    "        loss_history = softmax.train(X_train, y_train, learning_rate=lr, reg=reg,\n",
    "                                     num_iters=2000, verbose=True)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        train_acc = np.sum((y_train_pred == y_train)) / y_train.shape[0]\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        val_acc = np.sum((y_val_pred == y_val)) / y_val.shape[0]\n",
    "        if(val_acc > best_val):\n",
    "            best_val=val_acc\n",
    "            best_softmax=softmax\n",
    "    results[(lr,reg)]=(train_acc,val_acc)\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a1f9db3",
   "metadata": {
    "test": "test"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.397000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9b65c",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$\n",
    "\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "009f08b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569b36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
